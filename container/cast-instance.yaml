cpuPlatform: Intel Broadwell
creationTimestamp: '2025-01-30T08:42:09.028-08:00'
deletionProtection: false
description: CAST.AI managed GKE cluster node
disks:
- architecture: X86_64
  autoDelete: true
  boot: true
  deviceName: persistent-disk-0
  diskSizeGb: '150'
  guestOsFeatures:
  - type: SEV_LIVE_MIGRATABLE
  - type: VIRTIO_SCSI_MULTIQUEUE
  - type: SEV_SNP_CAPABLE
  - type: SEV_CAPABLE
  - type: SEV_LIVE_MIGRATABLE_V2
  - type: GVNIC
  - type: UEFI_COMPATIBLE
  - type: IDPF
  index: 0
  interface: SCSI
  kind: compute#attachedDisk
  licenses:
  - https://www.googleapis.com/compute/v1/projects/cos-cloud/global/licenses/cos-pcid
  - https://www.googleapis.com/compute/v1/projects/cos-cloud-shielded/global/licenses/shielded-cos
  - https://www.googleapis.com/compute/v1/projects/gke-node-images/global/licenses/gke-node
  - https://www.googleapis.com/compute/v1/projects/cos-cloud/global/licenses/cos
  mode: READ_WRITE
  shieldedInstanceInitialState:
    dbs:
    - content: MIIEDTCCAvWgAwIBAgIQRtEbux4j2WDjYimBMkIBYjANBgkqhkiG9w0BAQsFADCBizELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDU1vdW50YWluIFZpZXcxFDASBgNVBAoTC0dvb2dsZSBMTEMuMR8wHQYDVQQLExZDb250YWluZXIgT3B0aW1pemVkIE9TMRgwFgYDVQQDEw9VRUZJIERCIEtleSB2MTAwHhcNMjAwODA2MTk0ODU1WhcNMzAwODA0MTk0ODU1WjCBizELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDU1vdW50YWluIFZpZXcxFDASBgNVBAoTC0dvb2dsZSBMTEMuMR8wHQYDVQQLExZDb250YWluZXIgT3B0aW1pemVkIE9TMRgwFgYDVQQDEw9VRUZJIERCIEtleSB2MTAwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDQzJHu5A61uBNU6UUUZ5MiXjXwy8Du44BHhisNBpi6cTVHZddJ85iNldE5cPL7hZFJP9n77KyFRCCLxT2CVDNkwMyE2jvJkTz2x2qWvJ-uIuL25Asfgbrv7t1h2Jn790ZLwb9U3qQvqMLvIh_cTtNLat0DaZJsdnJo1MTnFAWrYZZ19KB4j6JJpG_QBnQ-s8XibeSSoa_bMEQTn2OEQFeEcume3CeuZKzXyytMLKkV_z4z-CYddyRwkOFivWUHWq2nVecQQgdyDNWYxGnY4MNsTMYFfv-mhyRzMwhxBFMwMAaEwhTFWsIP6VNwrwIgQaDw3o1fUEuzavTfdNhULaJLAgMBAAGjazBpMA8GA1UdEwEB_wQFMAMBAf8wKQYDVR0OBCIEIEtOsnFY2N1KW7dg9Wd_GEcIwV_a-U2DCn5ZyUsGWickMCsGA1UdIwQkMCKAIEtOsnFY2N1KW7dg9Wd_GEcIwV_a-U2DCn5ZyUsGWickMA0GCSqGSIb3DQEBCwUAA4IBAQCOd9V3WYv589dVov5ZOYo4zSs5PXpts1_8sYvMwvzLBr46LaejfG7KjjIY665Cnik__Zy9N3ZS9-fEeGKrBPE8ClwC06QhLbWDSFIqj2y9qq5FyBW0k1no2UQBnvx4CnLw_BgU3eae0wjv1lpDIbMwxe3E_aucVmzaIX3O83cw2JL9lLm1Psum0L2VHDZSCTP24vzrWoXXo4USHO_tBt_NkYrdkQH5CqGJYtxzKRwHHKEar3vzsiW4DPzlW8kUjRual1eBOKT5YKGbrOA_PJXV9x_7v1f2uAIrqh3HyppDTaGJ7Lux1MDf_hKuwAFI5QJTy9NEojbuUk1tzB4ys_W8
      fileType: X509
    dbxs:
    - content: MIIEaDCCA1CgAwIBAgIJAKqfsrCdjyCoMA0GCSqGSIb3DQEBCwUAMH8xCzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1Nb3VudGFpbiBWaWV3MRQwEgYDVQQKEwtHb29nbGUgTExDLjEUMBIGA1UECxMLQ2hyb21pdW0gT1MxFzAVBgNVBAMTDlVFRkkgREIgS2V5IHYxMB4XDTE4MTIwODAxMTk0MVoXDTI4MTIwNTAxMTk0MVowfzELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDU1vdW50YWluIFZpZXcxFDASBgNVBAoTC0dvb2dsZSBMTEMuMRQwEgYDVQQLEwtDaHJvbWl1bSBPUzEXMBUGA1UEAxMOVUVGSSBEQiBLZXkgdjEwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCtZ9U4P5aWlBwiTocmkUjOn2XpvHUlUOnsnhvsm994hAb0MNk2d3fXa8Nz14v9JiBTSf70KU2Zhxb_bSN3KAIv-f7F2AuXte7U9SnzZ02UDmK4TU1bFQW67Y3Gc2hWprCHYEjiRQD4J3WPWhuZnAXqzXQk3uDWVPETi-G9KAM1R-yNxZfoEjfIKhLabDsWqDtnMSovObLoVfwTdnm0WCuYTFtY_CKNxuxeKuzDsC5Su9N3dSFbpGhXJjwUaXPLWY5MFIqIQNBfhmWzDd4PItXaXV3V44IqWTXclE2aSUqkwNrEZ1cRpHG4PYM1aHVmjcO_dWlvthcepTIMIEMAXg2LAgMBAAGjgeYwgeMwHQYDVR0OBBYEFNXbmmdkM0aIsPMyEIv25JRaOPA-MIGzBgNVHSMEgaswgaiAFNXbmmdkM0aIsPMyEIv25JRaOPA-oYGEpIGBMH8xCzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1Nb3VudGFpbiBWaWV3MRQwEgYDVQQKEwtHb29nbGUgTExDLjEUMBIGA1UECxMLQ2hyb21pdW0gT1MxFzAVBgNVBAMTDlVFRkkgREIgS2V5IHYxggkAqp-ysJ2PIKgwDAYDVR0TBAUwAwEB_zANBgkqhkiG9w0BAQsFAAOCAQEAJ2vbNymAKTUbRvxnAohHozVUByrKHCq1o8b-bKrgv7Ch0X4itfG8Uwvt0xG7CTpl_Dno92MtpOpFv4ydqox-pP1kTsRcnFNggndXdjpGILIB94KmFiYJvB6RzocJsXsXBa0tULOR24qiB9f93kfITS7Ec60WjFfpgYKEnuEgcV0yBuZzAZbxo1uF4n1hhmVUnKtEI9pX-8geYIIqIYiwwT2jnhFogWw4PeSyg-HMR1CLwwJeH2XDa924LpgHFuR-AbikipAE2vIE0yqJzo0o4tn9-sRuMaQcZ4VQqIzMiniW5H7nGeoQY3ktHX5eq6x-4jFvdLnzzq_D4sS-UWHzOA==
      fileType: X509
    - content: MIIEiTCCA3GgAwIBAgIJAOzm3xz71Vu6MA0GCSqGSIb3DQEBCwUAMIGJMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEUMBIGA1UEChMLR29vZ2xlIExMQy4xFDASBgNVBAsTC0Nocm9taXVtIE9TMSEwHwYDVQQDExhVRUZJIEtleSBFeGNoYW5nZSBLZXkgdjEwHhcNMTgxMjA4MDExOTQwWhcNMjgxMjA1MDExOTQwWjCBiTELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDU1vdW50YWluIFZpZXcxFDASBgNVBAoTC0dvb2dsZSBMTEMuMRQwEgYDVQQLEwtDaHJvbWl1bSBPUzEhMB8GA1UEAxMYVUVGSSBLZXkgRXhjaGFuZ2UgS2V5IHYxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAwg5hvVH6fJSBNji7ynBl1SQzWceL5P3ul6RcB-1s5wXqzXlIHiyRqBdj4hj2pLzpKJGmXWnerIwJOkdsFg7IwZpA4xHE1F-M8XlpuuUn_Xdfccef36ddZEUH6QLwNm96T89F4ujt0omJ-0GV37vBsxEY-hwR3O8XBgyx8TvvYxNnVyTgi19qQdb2ES8-yWJkebdzgugcmNf9K-55fnEiyxWtrvEQb2sowWIS3-b1I_BP85pW2pldh9yQWfb3OY2NJhGSbQSnLi3J0IhRXROEtAXCU4MLTq2cHOpGX0DtJP_g_jD1pnC1O6CCZgVycK4DgZXeDzOG_2Uimhr0y1rcewIDAQABo4HxMIHuMB0GA1UdDgQWBBQEqlpkrYWCzJe69eMUdF1byztBmzCBvgYDVR0jBIG2MIGzgBQEqlpkrYWCzJe69eMUdF1byztBm6GBj6SBjDCBiTELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDU1vdW50YWluIFZpZXcxFDASBgNVBAoTC0dvb2dsZSBMTEMuMRQwEgYDVQQLEwtDaHJvbWl1bSBPUzEhMB8GA1UEAxMYVUVGSSBLZXkgRXhjaGFuZ2UgS2V5IHYxggkA7ObfHPvVW7owDAYDVR0TBAUwAwEB_zANBgkqhkiG9w0BAQsFAAOCAQEAWsd3mq0dADTD7Tx2uYcDeJcJHO0x91hO26p2cqUSox4wPgc4_xk5yiteMgDB5CWLwgcuneDAYYMO1PmktpEvLu9a82gCGxGiww-w78OJTOrs68VM1zB0jqA3X5EyVSwVJqi8idgrnnGsJAcSBosnUI8pNi9SDC3MRPE1q1EUjuDNjsE7t_ItBe-MSMWCH2hpG8unZ7uwWCRfAV3Fkdnq_S5HzDy6-kKyGdj-rprhVeDz2xSyMOlNIJig4uuqU166DTfoQA2TxnMG_TuHt69Z4uZcVwx_HwPs2-vUCCYqZDwuuHKNIEm8kIK8sSPSsp22sC8h-7Klb8wj_d0lzShgkg==
      fileType: X509
    - content: MIID0zCCArugAwIBAgIJANuXsNG_1HHxMA0GCSqGSIb3DQEBCwUAMH8xCzAJBgNVBAYTAlVTMRMwEQYDVQQIDApDYWxpZm9ybmlhMRYwFAYDVQQHDA1Nb3VudGFpbiBWaWV3MRQwEgYDVQQKDAtHb29nbGUgTExDLjEUMBIGA1UECwwLQ2hyb21pdW0gT1MxFzAVBgNVBAMMDlVFRkkgREIgS2V5IHYxMCAXDTE4MDQyNzE1MDYzN1oYDzIyMTgwMzEwMTUwNjM3WjB_MQswCQYDVQQGEwJVUzETMBEGA1UECAwKQ2FsaWZvcm5pYTEWMBQGA1UEBwwNTW91bnRhaW4gVmlldzEUMBIGA1UECgwLR29vZ2xlIExMQy4xFDASBgNVBAsMC0Nocm9taXVtIE9TMRcwFQYDVQQDDA5VRUZJIERCIEtleSB2MTCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBALWzFg8obysKXCjnbBTpAM8dMFC2pHX7GpwESNG-FYQI218Y1Ao1p5BttGqPoU5lGNeYUXxgxIqfN18ALHH10gRCRfqbC54faPU1lMr0e0jvi67GgGztyLl4ltAgK7HHTHmtZwghYNS45pKz_LFGm-TlKg-HPZBFT9GtbjRZe5IS2xdKkWM_sPA8qXwzvqmLN3OQckf0KchSUQmB3-wh4vYFV2TEjz10oR0FZO8LFFOOeooukcRDYy219XrdM21APnfszHmfKhzAFddOcYdwKwOL-w9TKVUwCIM70GL_YOtywA17mQkEm0ON79oyQ0daDlZ0ngDxC8xUIASYsRRPOkkCAwEAAaNQME4wHQYDVR0OBBYEFFO6MYgG9CvYp6qAqn_Jm-MANGpvMB8GA1UdIwQYMBaAFFO6MYgG9CvYp6qAqn_Jm-MANGpvMAwGA1UdEwQFMAMBAf8wDQYJKoZIhvcNAQELBQADggEBAIGyOB_3oFo6f3WoFrdBzimb_weH8hejtCggpcL-8Wdex9VRl5MKi_1GlGbietMDsr1alwdaagam9RafuIQplohTSBnQrU-u-LbtRlCF9C25GDQ70S0QlxAQmt41Sc7kSFTPm6BHauF3b_Raf9AX30MamptoXoAhgMnHAitCn6yCOsRJ_d1t04lqsiqefhf26xItvRnkuxG7-IQnbyGFCGPcjFNAE1thLpL_6y_dprVwTLsvZnsWYj-1Gg1yUkOnCN8Kl3Q3RDVqo98mORUc0bKB-B8_FQsbtmzbb-29nXQJW1FJx0ejqJyDGGBPHAGpwEJTVB3mwWXzBU6Ny7T3dlk=
      fileType: X509
    - content: MIID6TCCAtGgAwIBAgIJAKgdcZ45rGMDMA0GCSqGSIb3DQEBCwUAMIGJMQswCQYDVQQGEwJVUzETMBEGA1UECAwKQ2FsaWZvcm5pYTEWMBQGA1UEBwwNTW91bnRhaW4gVmlldzEUMBIGA1UECgwLR29vZ2xlIExMQy4xFDASBgNVBAsMC0Nocm9taXVtIE9TMSEwHwYDVQQDDBhVRUZJIEtleSBFeGNoYW5nZSBLZXkgdjEwIBcNMTgwNDI3MTUwNjM3WhgPMjIxODAzMTAxNTA2MzdaMIGJMQswCQYDVQQGEwJVUzETMBEGA1UECAwKQ2FsaWZvcm5pYTEWMBQGA1UEBwwNTW91bnRhaW4gVmlldzEUMBIGA1UECgwLR29vZ2xlIExMQy4xFDASBgNVBAsMC0Nocm9taXVtIE9TMSEwHwYDVQQDDBhVRUZJIEtleSBFeGNoYW5nZSBLZXkgdjEwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCbIdHPMQZZU68jI5kz5rmwvo-DQZZJ5amRnAUnBpNllhNQB6TaLUS_D9TIo_0X1e8T21Xk4Pf3D5ckbuQxsJzQ5OVEOb59sJ9AhjVUoxQxuVW-iBzD0mWbxKf2cASy2YRIEcaAAI5QT2SwO8gZy_G8LwAk-vO0vIbynN0WuFLl1Dp2cMQ3CxLSPH-QPSZyGd6o6ewUU9JzboppujXpk43EQH5ZJE_wJb_ujUFWcFzKHb_EkV1hI1TmBJ1-vR2kao4_1hQO6k1zLUR-MyBHY0SRU2OQxBpSez-qt7oItMBc1EanXvq9tqx0ndCTmXQYQplT5wtkPbE9sd5zwbDt8btHAgMBAAGjUDBOMB0GA1UdDgQWBBS5Tmmv3JM8w1mfP9V5xAIdjBhb7TAfBgNVHSMEGDAWgBS5Tmmv3JM8w1mfP9V5xAIdjBhb7TAMBgNVHRMEBTADAQH_MA0GCSqGSIb3DQEBCwUAA4IBAQB9BRTP37ik4jF2BmJJspMA6NHS7mxIckFCYKl-TO8zGFd3mlA6dnEw5WY-tUcBNJpAaHNJV_rzagGPpWMIoy-nAaLSSpnyhEXYTnQvzejYRijN3N0V9tmM0qgViHNBqTxdfcwlst5OUesGHPqgBOt5RRu5OGJ0rkuymWwxHOKIw43hz5FW7vhumbtJ3iy8HSFQIjSYMkr0sOzJhmvnHlpZ4pOoPNyNA9DM6smriH-2-MnJFM9w8bg6zsV5X-6KL464_FuXL_X_IWmAsAbi8Ge8ZMJjEaDrF1qkD4aLvu0MshzEdvrvQO-3Gn3Lmi_RYKR0HKZp7jXTySj76sxt9QK4
      fileType: X509
    keks:
    - content: MIIEIjCCAwqgAwIBAgIRAKxVeWkn5a0pF1C0o_HUM6owDQYJKoZIhvcNAQELBQAwgZUxCzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1Nb3VudGFpbiBWaWV3MRQwEgYDVQQKEwtHb29nbGUgTExDLjEfMB0GA1UECxMWQ29udGFpbmVyIE9wdGltaXplZCBPUzEiMCAGA1UEAxMZVUVGSSBLZXkgRXhjaGFuZ2UgS2V5IHYxMDAeFw0yMDA4MDYxOTQ4NTBaFw0zMDA4MDQxOTQ4NTBaMIGVMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEUMBIGA1UEChMLR29vZ2xlIExMQy4xHzAdBgNVBAsTFkNvbnRhaW5lciBPcHRpbWl6ZWQgT1MxIjAgBgNVBAMTGVVFRkkgS2V5IEV4Y2hhbmdlIEtleSB2MTAwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC6ZCJ4Oldm1z3gwwAjWqiHRMFrXPwq0XmVmLWoaGUBzeL41VwHK76iQTxl11HYhqaAr_0nmVQAM3M6so6cmydd7l1RPYJpZ3Shy3qO4xxgy30kp4zW00m9EVEdkmh9-9zi_G89uutz7wOb34M2Wrybwa7D5U102DmSoJAoq5z2YrvpjZoGLRGqBBP6A1l-_gRGMAgUMqKbhD1HF1VKXZnIGq9UJcpHhRvQxOG3nlVWk6z8dH-Rnp_9YfEPRORAUF5PUnUL5-I3wr5derIIoeYxc7G2ZuTyRWsF9WVyZ7OquYwxAY4l4xkDJpAvSomHkbfNgtCZyTm2pMIkRou0up5lAgMBAAGjazBpMA8GA1UdEwEB_wQFMAMBAf8wKQYDVR0OBCIEINDkWV5HwgIi6aogGQUbZwWC5Es_Vx9SX5kG8i1xiXxKMCsGA1UdIwQkMCKAINDkWV5HwgIi6aogGQUbZwWC5Es_Vx9SX5kG8i1xiXxKMA0GCSqGSIb3DQEBCwUAA4IBAQCOTmuK7QQ4sP_8qYI2-bkvbQg1Vpq0W_aWtm0AQDw2iEVgfIq8JxNHu61ZhkmBiEhsdaaj7bYt_8owpvxfRnmzMPhQ6iB51vkExjWipD9spgSb8tfp0te6MqTT3omyYI9x4L13wn9ufZtlhZXlVgbjUN1QyevHwNt7Kms8Nd9Jbk9JCV9JoOIjkBpUjpCWCDfdGDD-iGIPzGdS-KjrNiA4udnzkdkO83dFMMvu69a1snCRUshNvHBNPbPRwbRYV9lS_QTwfft7EgbNF0455gblZbejvGJgR1Vhyen0jIPouVWxXe0X7AnGK8Mc3DUQBPVGT4ZR0WChbcwiOavh2t2X
      fileType: X509
    pk:
      content: MIIEGTCCAwGgAwIBAgIQYB8C9RH--O1hXkpp2FVSXjANBgkqhkiG9w0BAQsFADCBkTELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDU1vdW50YWluIFZpZXcxFDASBgNVBAoTC0dvb2dsZSBMTEMuMR8wHQYDVQQLExZDb250YWluZXIgT3B0aW1pemVkIE9TMR4wHAYDVQQDExVVRUZJIFBsYXRmb3JtIEtleSB2MTAwHhcNMjAwODA2MTk0ODQ0WhcNMzAwODA0MTk0ODQ0WjCBkTELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDU1vdW50YWluIFZpZXcxFDASBgNVBAoTC0dvb2dsZSBMTEMuMR8wHQYDVQQLExZDb250YWluZXIgT3B0aW1pemVkIE9TMR4wHAYDVQQDExVVRUZJIFBsYXRmb3JtIEtleSB2MTAwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQClSQ15LUf193eJfM6b5etGgz8auvdI72Cclo3fHvwXBzsm5T1QamwYAqrCTcS7MxauCTkmkXTS9ejM4NNpQWF6KG82nR88vRyKO_MnSNL8ZP-rtRu0p1X_mUYXwi0_nPkyPKLR2QJ9H2EOrw_RChWvwnu281WtfUPCYs2t2SjBCF_mgzZI8o3s8wOtL8y-Dmi9T0bGO1wYX2okz51PKbhgVGQA7KJRmeekIxEkiN7GOb_2VQqcdM9c846OlC-8abwgDvrL3YqKqhw8DnSM2AbNpZIgUTd1Ut3X-PWXVKBj3qdxjAyRez8dPWymXDji-CBoBzLsWEkUW87S1coggOABAgMBAAGjazBpMA8GA1UdEwEB_wQFMAMBAf8wKQYDVR0OBCIEIMk0-K2sxOjtSpl-2pXmBWwwvSMGEIThmdDsSxQk2XZQMCsGA1UdIwQkMCKAIMk0-K2sxOjtSpl-2pXmBWwwvSMGEIThmdDsSxQk2XZQMA0GCSqGSIb3DQEBCwUAA4IBAQA7Pmaixb0FuDtpesNGvaBkTGWWMO7bDtx4rQom7zprEnliFJZung08FS3r73ob1urH0lzZm9022nRp8xqcSGk3wDkE9xQppWhvjhf6SOHdwM9_OxVq6no_BPz1PkRYsg4V07cgYPCtp7Ck7ZBI7m3MbLUyg8EG14_tvjKX9Xh2h0FSGuGg8_jjGYCGDtaSPkXBpAWurZ5mC2o9CzGaBJR4f_51I5C2AfHMG0H5T0Kehuyb_IzX9mAwArGmt62e4T9SxdP7LZUNPMEzOrhW1RzXvsD6Vod4uA9h2n_lbZHiBBExM2PMwuoobb-io-W0ARL4OCN5jah0a7q1ax6UYJK-
      fileType: X509
  source: https://www.googleapis.com/compute/v1/projects/engineering-test-353509/zones/europe-central2-a/disks/gke-damian0130-cast-pool-4a209c2c
  type: PERSISTENT
fingerprint: G4jKJHqtcks=
id: '5242175173204251919'
kind: compute#instance
labelFingerprint: nQrphFtoLkk=
labels:
  cast-cluster-id: 0b3bc1eb-70da-4cde-96af-f672f80dfcc6
  cast-managed-by: cast-ai
  cast-node-id: 4a209c2c-28d3-471e-9312-9d207a6e2dd2
  cast-node-template: default-by-castai
  goog-gke-cluster-id-base32: dnnuh7mpfngyboonuxo5nsop4t5zlvogjgueqnuzc4jb4ykf73tq
  goog-gke-node: ''
  goog-k8s-cluster-location: europe-central2
  goog-k8s-cluster-name: damian0130
  goog-k8s-node-pool-name: cast-pool
  goog-terraform-provisioned: 'true'
  persist: 'true'
lastStartTimestamp: '2025-01-30T08:42:28.715-08:00'
machineType: https://www.googleapis.com/compute/v1/projects/engineering-test-353509/zones/europe-central2-a/machineTypes/e2-standard-2
metadata:
  fingerprint: eGqdEcHYz-k=
  items:
  - key: disable-legacy-endpoints
    value: 'true'
  - key: google-compute-enable-pcid
    value: 'true'
  - key: kubeconfig
    value: |
      apiVersion: v1
      kind: Config
      clusters:
      - cluster:
          server: https://10.0.0.2
          certificate-authority: '/etc/srv/kubernetes/pki/ca-certificates.crt'
        name: default-cluster
      contexts:
      - context:
          cluster: default-cluster
          namespace: default
          user: exec-plugin-auth
        name: default-context
      current-context: default-context
      users:
      - name: exec-plugin-auth
        user:
          exec:
            apiVersion: "client.authentication.k8s.io/v1beta1"
            command: '/home/kubernetes/bin/gke-exec-auth-plugin'
            args: ["--cache-dir", '/var/lib/kubelet/pki/']
  - key: cluster_name
    value: damian0130
  - key: cluster-uid
    value: 1b5b43fd8f2b4d80b9cda5ddd6c9cfe4fb95d5c649a848369917121e6145fee7
  - key: gci-metrics-enabled
    value: 'true'
  - key: gci-update-strategy
    value: update_disabled
  - key: configure-sh
    value: |
      #!/usr/bin/env bash

      # Copyright 2016 The Kubernetes Authors.
      #
      # Licensed under the Apache License, Version 2.0 (the "License");
      # you may not use this file except in compliance with the License.
      # You may obtain a copy of the License at
      #
      #     http://www.apache.org/licenses/LICENSE-2.0
      #
      # Unless required by applicable law or agreed to in writing, software
      # distributed under the License is distributed on an "AS IS" BASIS,
      # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
      # See the License for the specific language governing permissions and
      # limitations under the License.

      # Due to the GCE custom metadata size limit, we split the entire script into two
      # files configure.sh and configure-helper.sh. The functionality of downloading
      # kubernetes configuration, manifests, docker images, and binary files are
      # put in configure.sh, which is uploaded via GCE custom metadata.

      set -o errexit
      set -o nounset
      set -o pipefail

      ### Hardcoded constants

      DEFAULT_CNI_VERSION='v1.5.0-gke.3'
      DEFAULT_CNI_HASH_LINUX_AMD64='b53474f2a4109e9c54a4f526386a6311622e96b739109abdd77d7f063220c8be04f2b36e23f5c8eba37dc664b833b3a920acbfe04e170667835f30ccdbba0bbf'
      DEFAULT_CNI_HASH_LINUX_ARM64='32c0093c87fe46a4243d382b16184d98cd14411dfb590552baaad10d2ba115682c77e39ed60fffb9e06ed3e9ea666ee6618fd7ecbc81ba9f3b49e700991e5d38'

      DEFAULT_NPD_VERSION='v0.8.19-12-g5efc8884-gke.1'
      DEFAULT_NPD_HASH_AMD64='c9d652c18ab2e90f5b0de0384f0af7d9bb0abf14c7120828fdb8f1aad7950178195547cf9be49d4647e86366d2f4a462d2b9d3d7550840c48545a2268f97abd2'
      DEFAULT_NPD_HASH_ARM64='4520a9642525f6f271b76cfcb23a0d6a385860098d247aa63bc68b6b1e5aca198b50fd03c6354c8109e7f816260b47b4658ee70c617460dbb0263b7a7977e5a8'

      NPD_CUSTOM_PLUGINS_VERSION="v1.0.20"
      NPD_CUSTOM_PLUGINS_TAR_AMD64_HASH="0907d1949013577cb13f90d10274e37f4ff6962fb97d23454b38562966f31d0d50da960278da7353215ecc6ec777b7a87c2972f3244ba7a8c9444282cc5dd84c"
      NPD_CUSTOM_PLUGINS_TAR_ARM64_HASH="773062478605e5bf6d65c7e1374bff6b6cb2a99fc59ea46472c2fe4b15451f8547c740495961f1a9c50077ea67d16e32106733326d7e197dac60a07d8b05a375"

      DEFAULT_CRICTL_VERSION='v1.31.1-gke.0'
      DEFAULT_CRICTL_AMD64_SHA512='7c0ea3355b53c79e00772cfdf0bf67d262a9a0e827fdcf5be956ff68be25b47d7cb5cd6b065e3de251efc7b4534961e37a37b9f0e3f1efa22dfe2b5149702889'
      DEFAULT_CRICTL_ARM64_SHA512='05c8a74117288def73c430aa7f207432c2b0e6f0560bb795f90debb65902a76e1d001e876a319cdf090c78ca4cbafa8021dd1a93e938aa74fd800677020446f6'
      DEFAULT_MOUNTER_ROOTFS_VERSION='v1.0.0'
      DEFAULT_MOUNTER_ROOTFS_TAR_AMD64_SHA512='631330b7fa911d67e400b1d014df65a7763667d4afd4ecefe11a4a89dc9b8be626e5610d53b536c255a3ab488408ab2da8a0699d9fdad280cb3aa24bc2f30ab0'
      DEFAULT_MOUNTER_ROOTFS_TAR_ARM64_SHA512='83cf9ab7961627359654131abd2d4c4b72875d395c50cda9e417149b2eb53b784dfe5c2f744ddbccfe516e36dd64c716d69d161d8bc8b4f42a9207fe676d0bc1'

      RIPTIDE_FUSE_VERSION="v0.237.1.patch"
      RIPTIDE_FUSE_ARM64_SHA512='611a54c566cd156ee18f63b4f590cef6f044f4dd3f4ad77164a2f03e2ea00db1902c2253ac03eb760332aee214cf28a852f41075113b0350a478e01fcad641bd'
      RIPTIDE_FUSE_BIN_ARM64_SHA512='bf17276292fb7b9acf76a3b80a4f7023cf1e97f64df6feef23940be3dfdeeecdfacbaf8babc754a9280a9d22f0d1039eee3c0d59fcd0951b7a3228c35a68d4c8'
      RIPTIDE_FUSE_AMD64_SHA512='d28deb2df0ef7d60fe520113f4e59dd4d0238713b2e99d8147a3e101c8c2e91f830296601cdb1044880ac9709bd33f461b7c60fa301254889d733f7a653e569d'
      RIPTIDE_FUSE_BIN_AMD64_SHA512='d62c20fa299c738359b400da2171bafbcf4550b77de74dcfa53cf86b5a6c480b4ae91fe9c2cc564e188e4fb60f7cf3b6448199cd147105c655e37583a93c80e3'

      RIPTIDE_SNAPSHOTTER_VERSION="v1.31-1"
      RIPTIDE_SNAPSHOTTER_SHA512='f8ea490a719e4e3dd3177f48f85e066802173e36a8bdcfcc1e5507f05c88ac8296fd9a82e79292e23007c7e574dc054d28ac405427c9f4eb9778270339bf24e8'
      RIPTIDE_SNAPSHOTTER_BIN_ARM64_SHA512='1d7d0dd3ce52f831adba1037142e6b315e2de7919e8fa4ab86892d353e2a642697915011c165a20386b047acf8c7a5764a9674569746f141f0376f0060671b9f'
      RIPTIDE_SNAPSHOTTER_BIN_AMD64_SHA512='1e81cee5ac33bef018029ddd39db307c3f0044bc9ac52621066094e05ea4e87ece75294be19de21875dbd2a65d1a52ce03f7b2fec132d785d6485e25ee90c597'

      AUTH_PROVIDER_GCP_VERSION="v0.0.2-gke.4"
      AUTH_PROVIDER_GCP_HASH_LINUX_AMD64="156058e5b3994cba91c23831774033e0d505d6d8b80f43541ef6af91b320fd9dfaabe42ec8a8887b51d87104c2b57e1eb895649d681575ffc80dd9aee8e563db"
      AUTH_PROVIDER_GCP_HASH_LINUX_ARM64="1aa3b0bea10a9755231989ffc150cbfa770f1d96932db7535473f7bfeb1108bafdae80202ae738d59495982512e716ff7366d5f414d0e76dd50519f98611f9ab"

      # gke-exec-auth-plugin local version.
      # The URLs below are relative to ${STORAGE_ENDPOINT}/${EXEC_AUTH_PLUGIN_BUCKET}
      EXEC_AUTH_PLUGIN_BUCKET="gke-prod-binaries"
      EXEC_AUTH_PLUGIN_VERSION="internal/gke-internal-branch-v1-31/c41916da792183068bb56af4129dbd4718fa1708"
      EXEC_AUTH_PLUGIN_LINUX_AMD64_HASH="026795bdf3e8cb1d384e1f69d7f01ad35221fd57a2dc7e778d9a9847f0b987d3cce38f4fcc20234bba405a6796723687ca40c130837b7e74fafdd99f74566e9c"
      EXEC_AUTH_PLUGIN_LINUX_ARM64_HASH="71aa357a8c3f7d4216a6a58d1a9a0f952df131bb2ba53d83308f2f234fdba7d165501b4842fbeaea9db0e0b3126b084538c44bf4c644733a3a578822b396d5f4"

      ###

      # Backend endpoints (configurable for TPC).
      # May be overridden when kube-env is sourced.
      #
      # NOTE: Endpoints should behave exactly like a GDU (Google Default Universe)
      # endpoint. E.g., An alternative `STORAGE_ENDPOINT` must have the same buckets
      # and paths as the `storage.googleapis.com` that this script depends on.
      STORAGE_ENDPOINT="${STORAGE_ENDPOINT:-https://storage.googleapis.com}"
      PGA_ENDPOINT="${PGA_ENDPOINT:-private.googleapis.com}"
      KUBE_DOCKER_REGISTRY="${KUBE_DOCKER_REGISTRY:-gke.gcr.io}"

      # Whether to configure private google access or not (defaults to true).
      # May be overridden when kube-env is sourced.
      CONFIGURE_PGA="${CONFIGURE_PGA:-true}"

      # Standard curl flags.
      CURL_FLAGS='--fail --silent --show-error --retry 5 --retry-delay 3 --connect-timeout 10 --retry-connrefused'

      # This version needs to be the same as in gke/cluster/gce/gci/configure-helper.sh
      GKE_CONTAINERD_INFRA_CONTAINER="pause:3.8@sha256:880e63f94b145e46f1b1082bb71b85e21f16b99b180b9996407d61240ceb9830"

      # Set max reboot retry 3 plus the inital boot count
      MAX_BOOT_COUNT="${MAX_BOOT_COUNT:-4}"

      function set-broken-motd {
        cat > /etc/motd <<EOF
      Broken (or in progress) Kubernetes node setup! Check the cluster initialization status
      using the following commands.

      Master instance:
        - sudo systemctl status kube-master-installation
        - sudo systemctl status kube-master-configuration

      Node instance:
        - sudo systemctl status kube-node-installation
        - sudo systemctl status kube-node-configuration
      EOF
      }

      # A function that fetches a GCE metadata value and echoes it out.
      # Args:
      #   $1 : URL path after /computeMetadata/v1/ (without heading slash).
      #   $2 : An optional default value to echo out if the fetch fails.
      #
      # NOTE: this function is duplicated in configure-helper.sh, any changes here
      # should be duplicated there as well.
      function get-metadata-value {
        local default="${2:-}"

        local status
        # shellcheck disable=SC2086
        curl ${CURL_FLAGS} \
          -H 'Metadata-Flavor: Google' \
          "http://metadata/computeMetadata/v1/${1}" \
        || status="$?"
        status="${status:-0}"

        if [[ "${status}" -eq 0 || -z "${default}" ]]; then
          return "${status}"
        else
          echo "${default}"
        fi
      }

      # A function to fetch kube-env from GCE metadata server
      # or using hurl on the master if available
      function download-kube-env {
        (
          umask 077
          local kube_env_path="/tmp/kube-env.yaml"
          if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
            local kube_env_path="${KUBE_HOME}/kube-env.yaml"
            download-kube-env-hurl "${kube_env_path}"
          else
            local meta_path="http://metadata.google.internal/computeMetadata/v1/instance/attributes/kube-env"
            echo "Downloading kube-env via GCE metadata from ${meta_path} to ${kube_env_path}"
            # shellcheck disable=SC2086
            retry-forever 10 curl ${CURL_FLAGS} \
              -H "X-Google-Metadata-Request: True" \
              -o "${kube_env_path}" \
              "${meta_path}"
          fi

          # Convert the yaml format file into a shell-style file.
          eval "$(python3 -c '''
      import pipes,sys,yaml
      items = yaml.load(sys.stdin, Loader=yaml.BaseLoader).items()
      for k, v in items:
          print("readonly {var}={value}".format(var=k, value=pipes.quote(str(v))))
      ''' < "${kube_env_path}" > "${KUBE_HOME}/kube-env")"

          # Leave kube-env if we are a master
          if [[ "${KUBERNETES_MASTER:-}" != "true" ]]; then
            rm -f "${kube_env_path}"
          fi
        )
      }

      # A function to pull kube-env from HMS using hurl
      function download-kube-env-hurl {
        local -r kube_env_path="$1"
        local -r endpoint=$(get-metadata-value "instance/attributes/gke-api-endpoint")
        local -r kube_env_hms_path=$(get-metadata-value "instance/attributes/kube-env-path")

        echo "Downloading kube-env via hurl from ${kube_env_hms_path} to ${kube_env_path}"
        retry-forever 30 ${KUBE_HOME}/bin/hurl --hms_address $endpoint \
          --dst "${kube_env_path}" \
          "${kube_env_hms_path}"
        chmod 600 "${kube_env_path}"
      }

      function download-kubelet-config {
        local -r dest="$1"
        echo "Downloading Kubelet config file, if it exists"
        # Fetch kubelet config file from GCE metadata server.
        (
          umask 077
          local -r tmp_kubelet_config="/tmp/kubelet-config.yaml"
          # shellcheck disable=SC2086
          retry-forever 10 curl ${CURL_FLAGS} \
            -H "X-Google-Metadata-Request: True" \
            -o "${tmp_kubelet_config}" \
            http://metadata.google.internal/computeMetadata/v1/instance/attributes/kubelet-config
          # only write to the final location if curl succeeds
          mv "${tmp_kubelet_config}" "${dest}"
        )
      }

      # A function to pull kube-master-certs from HMS using hurl
      function download-kube-master-certs-hurl {
        local -r endpoint=$(get-metadata-value "instance/attributes/gke-api-endpoint")
        local -r tmp_kube_master_certs_path="/tmp/kube-master-certs.yaml"
        local -r kube_master_certs_path="${KUBE_HOME}/kube-master-certs"
        local -r kube_master_certs_hms_path=$(get-metadata-value "instance/attributes/kube-master-certs-path")

        echo "Downloading kube-master-certs via hurl from ${kube_master_certs_hms_path} to ${tmp_kube_master_certs_path}"
        retry-forever 30 ${KUBE_HOME}/bin/hurl --hms_address $endpoint \
          --dst "${tmp_kube_master_certs_path}" \
          "${kube_master_certs_hms_path}"

        # Convert the yaml format file into a shell-style file.
        eval "$(python3 -c '''
      import pipes,sys,yaml
      items = yaml.load(sys.stdin, Loader=yaml.BaseLoader).items()
      for k, v in items:
          print("readonly {var}={value}".format(var=k, value=pipes.quote(str(v))))
      ''' < "${tmp_kube_master_certs_path}" > "${kube_master_certs_path}")"

        # Remove the temp certs and strip perms for other users
        rm -f "${tmp_kube_master_certs_path}"
        chmod 600 "${kube_master_certs_path}"
      }

      function validate-hash {
        local -r file="$1"
        local -r expected="$2"

        actual_sha1=$(sha1sum "${file}" | awk '{ print $1 }') || true
        actual_sha512=$(sha512sum "${file}" | awk '{ print $1 }') || true
        if [[ "${actual_sha1}" != "${expected}" ]] && [[ "${actual_sha512}" != "${expected}" ]]; then
          echo "== ${file} corrupted, sha1 ${actual_sha1}/sha512 ${actual_sha512} doesn't match expected ${expected} =="
          return 1
        fi
      }

      # Get default service account credentials of the VM.
      GCE_METADATA_INTERNAL="http://metadata.google.internal/computeMetadata/v1/instance"
      function get-credentials {
        # shellcheck disable=SC2086
        curl ${CURL_FLAGS} \
          -H "Metadata-Flavor: Google" \
          "${GCE_METADATA_INTERNAL}/service-accounts/default/token" \
        | python3 -c 'import sys; import json; print(json.loads(sys.stdin.read())["access_token"])'
      }

      function valid-storage-scope {
        # shellcheck disable=SC2086
        curl ${CURL_FLAGS} \
          -H "Metadata-Flavor: Google" \
          "${GCE_METADATA_INTERNAL}/service-accounts/default/scopes" \
        | grep -E "auth/devstorage|auth/cloud-platform"
      }

      # Retry a download until we get it. Takes a hash and a set of URLs.
      #
      # $1 is the sha512/sha1 hash of the URL. Can be "" if the sha512/sha1 hash is unknown.
      # $2+ are the URLs to download.
      # env var FORCE_USE_CREDENTIAL indicates whether to force using credential.
      function download-or-bust {
        if [[ "${ARTIFACT_DOWNLOAD_RESTRICTED:-}" == "true" ]]; then
          echo "Cannot download: $* as downloading is restricted, exiting"
          exit 1
        fi

        local -r hash="$1"
        shift 1

        while true; do
          for url in "$@"; do
            local file="${url##*/}"
            rm -f "${file}"
            # if the url belongs to GCS API we should use oauth2_token in the headers if the VM service account has storage scopes
            local curl_headers=""

            if [[ "$url" =~ ^${STORAGE_ENDPOINT}/.* ]] || [[ "${FORCE_USE_CREDENTIAL:-false}" == "true" ]] ; then
              local canUseCredentials=0

              echo "Getting the scope of service account configured for VM."
              if ! valid-storage-scope ; then
                canUseCredentials=1
                # this behavior is preserved for backward compatibility. We want to fail fast if SA is not available
                # and try to download without SA if scope does not exist on SA
                echo "No service account or service account without storage scope. Attempt to download without service account token."
              fi

              if [[ "${canUseCredentials}" == "0" ]] ; then
                echo "Getting the service account access token configured for VM."
                local access_token="";
                if access_token=$(get-credentials); then
                  echo "Service account access token is received. Downloading ${url} using this token."
                else
                  echo "Cannot get a service account token. Exiting."
                  exit 1
                fi

                curl_headers=${access_token:+Authorization: Bearer "${access_token}"}
              fi
            fi
            if ! curl ${curl_headers:+-H "${curl_headers}"} -f --ipv4 -Lo "${file}" --connect-timeout 20 --retry 6 --retry-delay 10 --retry-connrefused "${url}"; then
              echo "== Failed to download ${url}. Retrying. =="
            elif [[ -n "${hash}" ]] && ! validate-hash "${file}" "${hash}"; then
              echo "== Hash validation of ${url} failed. Retrying. =="
            else
              if [[ -n "${hash}" ]]; then
                echo "== Downloaded ${url} (HASH = ${hash}) =="
              else
                echo "== Downloaded ${url} =="
              fi
              return
            fi
          done
        done
      }

      function record-preload-info {
        echo "$1,$2" >> "${KUBE_HOME}/preload_info"
        echo "Recording preload info for ${1} ${2}"
      }

      function is-preloaded {
        local -r key=$1
        local -r value=$2

        if ! grep -qs "${key},${value}" "${KUBE_HOME}/preload_info"; then
          if [[ "${ARTIFACT_DOWNLOAD_RESTRICTED:-}" == "true" ]]; then
            echo "No preload record found for ${key} and ${value} and downloading is restricted, exiting"
            exit 1
          fi
          if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
            echo "No preload record found for ${key} and ${value}"
          fi
          return 1
        fi
      }

      function is-ubuntu {
        [[ -f "/etc/os-release" && $(grep ^NAME= /etc/os-release) == 'NAME="Ubuntu"' ]]
      }

      function split-commas {
        echo -e "${1//,/'\n'}"
      }

      function remount-flexvolume-directory {
        local -r flexvolume_plugin_dir=$1
        mkdir -p "$flexvolume_plugin_dir"
        mount --bind "$flexvolume_plugin_dir" "$flexvolume_plugin_dir"
        mount -o remount,exec "$flexvolume_plugin_dir"
      }

      function install-gci-mounter-tools {
        CONTAINERIZED_MOUNTER_HOME="${KUBE_HOME}/containerized_mounter"
        if [[ -n "${MOUNTER_ROOTFS_VERSION:-}" ]]; then
            local -r mounter_rootfs_version="${MOUNTER_ROOTFS_VERSION}"
            local -r mounter_rootfs_tar_sha="${MOUNTER_ROOTFS_TAR_SHA512}"
        else
          local -r mounter_rootfs_version="${DEFAULT_MOUNTER_ROOTFS_VERSION}"
          case "${HOST_PLATFORM}/${HOST_ARCH}" in
            linux/amd64)
              local -r mounter_rootfs_tar_sha="${DEFAULT_MOUNTER_ROOTFS_TAR_AMD64_SHA512}"
              ;;
            linux/arm64)
              local -r mounter_rootfs_tar_sha="${DEFAULT_MOUNTER_ROOTFS_TAR_ARM64_SHA512}"
              ;;
            *)
              echo "Unrecognized version and platform/arch combination:"
              echo "$mounter_rootfs_version $HOST_PLATFORM/$HOST_ARCH"
              echo "Set MOUNTER_ROOTFS_VERSION and MOUNTER_ROOTFS_TAR_SHA512 to overwrite"
              exit 1
              ;;
          esac
        fi

        if is-preloaded "mounter" "${mounter_rootfs_tar_sha}"; then
          echo "mounter is preloaded."
          return
        fi

        echo "Downloading gci mounter tools."
        mkdir -p "${CONTAINERIZED_MOUNTER_HOME}"
        chmod a+x "${CONTAINERIZED_MOUNTER_HOME}"

        # Copy the mounter binary downloaded with the k8s binaries tar file
        cp "${KUBE_HOME}/kubernetes/server/bin/mounter" "${CONTAINERIZED_MOUNTER_HOME}/mounter"
        chmod a+x "${CONTAINERIZED_MOUNTER_HOME}/mounter"
        # Download the debian rootfs required for the mounter container
        mkdir -p "${CONTAINERIZED_MOUNTER_HOME}/rootfs"
        local -r mounter_rootfs_tar="containerized-mounter-${mounter_rootfs_version}_${HOST_PLATFORM}_${HOST_ARCH}.tar.gz"
        download-or-bust "${mounter_rootfs_tar_sha}" "${STORAGE_ENDPOINT}/gke-release/containerized-mounter/${mounter_rootfs_version}/${mounter_rootfs_tar}"
        mv "${KUBE_HOME}/${mounter_rootfs_tar}" "/tmp/${mounter_rootfs_tar}"
        tar xzf "/tmp/${mounter_rootfs_tar}" -C "${CONTAINERIZED_MOUNTER_HOME}/rootfs"
        rm "/tmp/${mounter_rootfs_tar}"
        mkdir -p "${CONTAINERIZED_MOUNTER_HOME}/rootfs/var/lib/kubelet"

        record-preload-info "mounter" "${mounter_rootfs_tar_sha}"
      }

      function docker-installed {
          if systemctl cat docker.service &> /dev/null ; then
              return 0
          else
              return 1
          fi
      }

      function disable_aufs() {
        # disable aufs module if aufs is loaded
        if lsmod | grep "aufs" &> /dev/null ; then
          sudo modprobe -r aufs
        fi
      }

      function detect_mtu {
        local MTU=1460
        if [[ "${DETECT_MTU:-}" == "true" ]];then
          local default_nic=$(ip route get 8.8.8.8 | sed -nr "s/.*dev ([^\ ]+).*/\1/p")
          if [ -f "/sys/class/net/$default_nic/mtu" ]; then
            MTU=$(cat /sys/class/net/$default_nic/mtu)
          fi
        fi
        echo $MTU
      }

      # This function cofigures docker. It has no conditional logic.
      # It will restart docker service so new settings will be picked up.
      # This method cannot be preloaded as the boot disk changes will not be persistet thru the reboots.
      function assemble-docker-flags {
        # log the contents of the /etc/docker/daemon.json if already exists
        if [ -f /etc/docker/daemon.json ]; then
          echo "Contents of the old docker config"
          cat /etc/docker/daemon.json
        fi

        disable_aufs

        # COS and Ubuntu have different docker options configured as command line arguments.
        # Use systemctl show docker to see the full list of options.
        # When configuring Docker options you can use daemon.json or command line arguments
        # The same option cannot be configured by both, even if it is a list option and can be repeated in the command line multiple times.
        # This is why we are not simply configuring everything in daemon.json.

        local MTU="$(detect_mtu)"

        # options to be set on COS, registry-mirror is pre-configured on COS
        local os_specific_options="\"live-restore\": true,\
         \"storage-driver\": \"overlay2\",\
         \"mtu\": ${MTU},"

        if is-ubuntu; then
          # Ubuntu already have everthing set
          os_specific_options=""
        fi

        # Important setting: set docker0 cidr to private ip address range to avoid conflict with cbr0 cidr range ("bip": "169.254.123.1/24")
        cat > /etc/docker/daemon.json <<EOF
      {
        "pidfile": "/var/run/docker.pid",
        "iptables": false,
        "ip-masq": false,
        "log-level": "warn",
        "bip": "169.254.123.1/24",
        "log-driver": "json-file",
        ${os_specific_options}
        "log-opts": {
            "max-size": "10m",
            "max-file": "5"
        }
      }
      EOF

        # Do not move to the daemon.json file for backward compatibility.
        # Command line and config file options cannot be both defined and custoemr customization may break.
        # insecure-registry setting was inherited from the past, see b/203231428. Keeping for backward compatibility.
        echo "DOCKER_OPTS=\"--registry-mirror=https://mirror.gcr.io --insecure-registry 10.0.0.0/8\"" > /etc/default/docker

        echo "Docker command line and configuration are updated. Restart docker to pick it up"
        systemctl restart docker
      }

      # Install node problem detector binary.
      function install-node-problem-detector {
        if [[ -n "${NODE_PROBLEM_DETECTOR_VERSION:-}" ]]; then
            local -r npd_version="${NODE_PROBLEM_DETECTOR_VERSION}"
            local -r npd_hash="${NODE_PROBLEM_DETECTOR_TAR_HASH}"
        else
            local -r npd_version="${DEFAULT_NPD_VERSION}"
            case "${HOST_PLATFORM}/${HOST_ARCH}" in
              linux/amd64)
                local -r npd_hash="${DEFAULT_NPD_HASH_AMD64}"
                ;;
              linux/arm64)
                local -r npd_hash="${DEFAULT_NPD_HASH_ARM64}"
                ;;
              # no other architectures are supported currently.
              # Assumption is that this script only runs on linux,
              # see cluster/gce/windows/k8s-node-setup.psm1 for windows
              # https://github.com/kubernetes/node-problem-detector/releases/
              *)
                echo "Unrecognized version and platform/arch combination:"
                echo "$DEFAULT_NPD_VERSION $HOST_PLATFORM/$HOST_ARCH"
                echo "Set NODE_PROBLEM_DETECTOR_VERSION and NODE_PROBLEM_DETECTOR_TAR_HASH to overwrite"
                exit 1
                ;;
            esac
        fi
        local -r npd_tar="node-problem-detector-${npd_version}-${HOST_PLATFORM}_${HOST_ARCH}.tar.gz"

        if is-preloaded "${npd_tar}" "${npd_hash}"; then
          echo "${npd_tar} is preloaded."
          return
        fi

        echo "Downloading ${npd_tar}."
        local -r npd_release_path="${NODE_PROBLEM_DETECTOR_RELEASE_PATH:-${STORAGE_ENDPOINT}/gke-release}"
        download-or-bust "${npd_hash}" "${npd_release_path}/node-problem-detector/${npd_tar}"
        local -r npd_dir="${KUBE_HOME}/node-problem-detector"
        mkdir -p "${npd_dir}"
        tar xzf "${KUBE_HOME}/${npd_tar}" -C "${npd_dir}" --overwrite
        mv "${npd_dir}/bin"/* "${KUBE_BIN}"
        chmod a+x "${KUBE_BIN}/node-problem-detector"
        rmdir "${npd_dir}/bin"
        rm -f "${KUBE_HOME}/${npd_tar}"

        record-preload-info "${npd_tar}" "${npd_hash}"
      }

      # Install node problem detector custom plugins.
      function install-npd-custom-plugins {
        local -r version="${NPD_CUSTOM_PLUGINS_VERSION}"
        case "${HOST_PLATFORM}/${HOST_ARCH}" in
          linux/amd64)
            local -r hash="${NPD_CUSTOM_PLUGINS_TAR_AMD64_HASH}"
            ;;
          linux/arm64)
            local -r hash="${NPD_CUSTOM_PLUGINS_TAR_ARM64_HASH}"
            ;;
          *)
            echo "Unrecognized version and platform/arch combination:"
            echo "$NPD_CUSTOM_PLUGINS_VERSION $HOST_PLATFORM/$HOST_ARCH"
            exit 1
        esac
        local -r tar="npd-custom-plugins-${version}-${HOST_PLATFORM}-${HOST_ARCH}.tar.gz"

        if is-preloaded "${tar}" "${hash}"; then
          echo "${tar} is preloaded."
          return
        fi

        echo "Downloading ${tar}."
        download-or-bust "${hash}" "${STORAGE_ENDPOINT}/gke-release/npd-custom-plugins/${version}/${tar}"
        local -r dir="${KUBE_HOME}/npd-custom-plugins"
        mkdir -p "${dir}"
        tar xzf "${KUBE_HOME}/${tar}" -C "${dir}" --overwrite
        local -r kube_bin_dir="${KUBE_HOME}/bin"
        cp -r "${dir}/bins"/* "${kube_bin_dir}"
        rm -f "${KUBE_HOME}/${tar}"

        record-preload-info "${tar}" "${hash}"
      }

      function install-cni-binaries {
        local -r cni_version=${CNI_VERSION:-$DEFAULT_CNI_VERSION}
        if [[ -n "${CNI_VERSION:-}" ]]; then
          local -r cni_hash="${CNI_HASH:-}"
        else
          local -r cni_hash_var="DEFAULT_CNI_HASH_${HOST_PLATFORM^^}_${HOST_ARCH^^}"
          local -r cni_hash="${!cni_hash_var}"
        fi

        local -r cni_tar="cni-plugins-${HOST_PLATFORM}-${HOST_ARCH}-${cni_version}.tgz"
        local -r cni_url="${STORAGE_ENDPOINT}/gke-release/cni-plugins/${cni_version}/${cni_tar}"

        if is-preloaded "${cni_tar}" "${cni_hash}"; then
          echo "${cni_tar} is preloaded."
          return
        fi

        echo "Downloading cni binaries"
        download-or-bust "${cni_hash}" "${cni_url}"
        local -r cni_dir="${KUBE_HOME}/cni"
        mkdir -p "${cni_dir}/bin"
        tar xzf "${KUBE_HOME}/${cni_tar}" -C "${cni_dir}/bin" --overwrite
        mv "${cni_dir}/bin"/* "${KUBE_BIN}"
        rmdir "${cni_dir}/bin"
        rm -f "${KUBE_HOME}/${cni_tar}"

        record-preload-info "${cni_tar}" "${cni_hash}"
      }

      # Install crictl binary.
      # Assumptions: HOST_PLATFORM and HOST_ARCH are specified by calling detect_host_info.
      function install-crictl {
        if [[ -n "${CRICTL_VERSION:-}" ]]; then
          local -r crictl_version="${CRICTL_VERSION}"
          local -r crictl_hash="${CRICTL_TAR_HASH}"
        else
          local -r crictl_version="${DEFAULT_CRICTL_VERSION}"
          case "${HOST_PLATFORM}/${HOST_ARCH}" in
            linux/amd64)
              local -r crictl_hash="${DEFAULT_CRICTL_AMD64_SHA512}"
              ;;
            linux/arm64)
              local -r crictl_hash="${DEFAULT_CRICTL_ARM64_SHA512}"
              ;;
            *)
              echo "Unrecognized version and platform/arch combination:"
              echo "$DEFAULT_CRICTL_VERSION $HOST_PLATFORM/$HOST_ARCH"
              echo "Set CRICTL_VERSION and CRICTL_TAR_HASH to overwrite"
              exit 1
          esac
        fi
        local -r crictl="crictl-${crictl_version}-${HOST_PLATFORM}-${HOST_ARCH}.tar.gz"

        # Create crictl config file.
        cat > /etc/crictl.yaml <<EOF
      runtime-endpoint: ${CONTAINER_RUNTIME_ENDPOINT:-unix:///run/containerd/containerd.sock}
      EOF

        if is-preloaded "${crictl}" "${crictl_hash}"; then
          echo "crictl is preloaded"
          return
        fi

        echo "Downloading crictl"
        local -r crictl_path="${STORAGE_ENDPOINT}/gke-release/cri-tools/${crictl_version}"
        download-or-bust "${crictl_hash}" "${crictl_path}/${crictl}"
        tar xf "${crictl}"
        mv crictl "${KUBE_BIN}/crictl"
        rm -f "${crictl}"

        record-preload-info "${crictl}" "${crictl_hash}"
      }

      function preload-pause-image {
        local -r pause_image="${KUBE_DOCKER_REGISTRY}/${GKE_CONTAINERD_INFRA_CONTAINER}"
        local pause_sha="${GKE_CONTAINERD_INFRA_CONTAINER#*@}"
        if [ -z "$pause_sha" ]; then
          echo "found no digest in GKE_CONTAINERD_INFRA_CONTAINER"
        else
          for img in $(ctr -n=k8s.io images list -q | grep "${pause_sha}"); do
            echo "pause image ${img} of the same version is preloaded, retagging"
            if [[ "${pause_image}" != "${img}" ]]; then
              ctr -n=k8s.io image tag --force ${img} ${pause_image}
            fi
            return
          done
        fi

        # preloading pause image. It will be used in preloader and will be
        # useful for staging builds where access_token is needed to pull the image
        local access_token="";

        if access_token=$(get-credentials); then
          ctr -n=k8s.io image pull --user="oauth2accesstoken:${access_token}" "${pause_image}"
        else
          echo "No access token. Pulling without it."
          ctr -n=k8s.io image pull "${pause_image}"
        fi
        pin-docker-image "pause"
      }

      function install-exec-auth-plugin {
        # We always use the URL/VERSION/HASH
        # set at the top of this file,
        # Values from kube-env are ignored in this version.
        local -r plugin_base_url="${STORAGE_ENDPOINT}/${EXEC_AUTH_PLUGIN_BUCKET}/gke-exec-auth-plugin/${EXEC_AUTH_PLUGIN_VERSION}"
        case "${HOST_PLATFORM}_${HOST_ARCH}" in
          linux_amd64)
            local -r plugin_url="${plugin_base_url}/${HOST_PLATFORM}_${HOST_ARCH}/gke-exec-auth-plugin"
            local -r plugin_hash="${EXEC_AUTH_PLUGIN_LINUX_AMD64_HASH}"
            ;;

          linux_arm64)
            local -r plugin_url="${plugin_base_url}/${HOST_PLATFORM}_${HOST_ARCH}/gke-exec-auth-plugin"
            local -r plugin_hash="${EXEC_AUTH_PLUGIN_LINUX_ARM64_HASH}"
            ;;

          *)
            echo "Unrecognized version and platform/arch combination: ${HOST_PLATFORM}/${HOST_ARCH}"
            exit 1
        esac

        if is-preloaded "gke-exec-auth-plugin" "${plugin_hash}"; then
          echo "gke-exec-auth-plugin is preloaded"
          return
        fi

        echo "Downloading gke-exec-auth-plugin binary"
        download-or-bust "${plugin_hash}" "${plugin_url}"
        mv "${KUBE_HOME}/gke-exec-auth-plugin" "${KUBE_BIN}/gke-exec-auth-plugin"
        chmod a+x "${KUBE_BIN}/gke-exec-auth-plugin"

        local -r license_url="${plugin_base_url}/LICENSE"
        echo "Downloading gke-exec-auth-plugin license"
        download-or-bust "" "${license_url}"
        mv "${KUBE_HOME}/LICENSE" "${KUBE_BIN}/gke-exec-auth-plugin-license"

        record-preload-info "gke-exec-auth-plugin" "${plugin_hash}"
      }

      function install-kube-manifests {
        # Put kube-system pods manifests in ${KUBE_HOME}/kube-manifests/.
        local dst_dir="${KUBE_HOME}/kube-manifests"
        mkdir -p "${dst_dir}"
        local manifests_tar_urls
        while IFS= read -r url; do
          manifests_tar_urls+=("$url")
        done < <(split-commas "${KUBE_MANIFESTS_TAR_URL}")
        local -r manifests_tar="${manifests_tar_urls[0]##*/}"
        if [ -n "${KUBE_MANIFESTS_TAR_HASH:-}" ]; then
          local -r manifests_tar_hash="${KUBE_MANIFESTS_TAR_HASH}"
        else
          echo "Downloading k8s manifests hash (not found in env)"
          download-or-bust "" "${manifests_tar_urls[@]/.tar.gz/.tar.gz.sha512}"
          local -r manifests_tar_hash=$(cat "${manifests_tar}.sha512")
        fi

        if is-preloaded "${manifests_tar}" "${manifests_tar_hash}"; then
          echo "${manifests_tar} is preloaded."
          return
        fi

        echo "Downloading k8s manifests tar"
        download-or-bust "${manifests_tar_hash}" "${manifests_tar_urls[@]}"
        tar xzf "${KUBE_HOME}/${manifests_tar}" -C "${dst_dir}" --overwrite
        local -r kube_addon_registry="${KUBE_ADDON_REGISTRY:-k8s.gcr.io}"
        if [[ "${kube_addon_registry}" != "k8s.gcr.io" ]]; then
          find "${dst_dir}" \(-name '*.yaml' -or -name '*.yaml.in'\) -print0 | \
            xargs -0 sed -ri "s@(image:\s.*)k8s.gcr.io@\1${kube_addon_registry}@"
          find "${dst_dir}" \(-name '*.manifest' -or -name '*.json'\) -print0 | \
            xargs -0 sed -ri "s@(image\":\s+\")k8s.gcr.io@\1${kube_addon_registry}@"
        fi
        cp "${dst_dir}/kubernetes/gci-trusty/gci-configure-helper.sh" "${KUBE_BIN}/configure-helper.sh"
        cp "${dst_dir}/kubernetes/gci-trusty/configure-kubeapiserver.sh" "${KUBE_BIN}/configure-kubeapiserver.sh"
        if [[ -e "${dst_dir}/kubernetes/gci-trusty/gke-internal-configure-helper.sh" ]]; then
          cp "${dst_dir}/kubernetes/gci-trusty/gke-internal-configure-helper.sh" "${KUBE_BIN}/"
        fi
        if [[ -e "${dst_dir}/kubernetes/gci-trusty/node-registration-checker.sh" ]]; then
          cp "${dst_dir}/kubernetes/gci-trusty/node-registration-checker.sh" "${KUBE_BIN}/"
        fi
        cp "${dst_dir}/kubernetes/gci-trusty/health-monitor.sh" "${KUBE_BIN}/health-monitor.sh"
        cp "${dst_dir}/kubernetes/gci-trusty/networkd-monitor.sh" "${KUBE_BIN}/networkd-monitor.sh"

        rm -f "${KUBE_HOME}/${manifests_tar}"
        rm -f "${KUBE_HOME}/${manifests_tar}.sha512"

        record-preload-info "${manifests_tar}" "${manifests_tar_hash}"
      }

      # Installs hurl to ${KUBE_HOME}/bin/hurl if not already installed.
      function install-hurl {
        cd "${KUBE_HOME}"

        local -r hurl_bin="hurl"
        local -r hurl_gcs_att="instance/attributes/hurl-gcs-url"
        local -r hurl_gcs_url=${HURL_GCS_URL:-$(get-metadata-value "${hurl_gcs_att}")}
        local -r hurl_hash=${HURL_HASH:-$(get-metadata-value "instance/attributes/hurl-bin-hash")}

        ### Fallback to old logic in case hurl_hash is not set
        # extracting version from url, example:
        # $ echo "https://storage.googleapis.com/gke-master-startup/hurl/gke_master_hurl_20230824.00_p0/hurl" | sed -n 's/.*gke_master_hurl_\(.*\)\/hurl/\1/p'
        # 20230824.00_p0
        local -r hurl_version=$(echo "${hurl_gcs_url}" | sed -n 's/.*gke_master_hurl_\(.*\)\/hurl/\1/p')

        local -r hurl_preload_digest=${hurl_hash:-$hurl_version}

        if is-preloaded "${hurl_bin}" "${hurl_preload_digest}"; then
          echo "install-hurl: hurl already installed"
          return
        fi

        if [[ -z "${hurl_gcs_url}" ]]; then
          # URL not present in GCE Instance Metadata
          echo "install-hurl: Unable to find GCE metadata ${hurl_gcs_att}"
          return
        fi

        # Download hurl binary from a GCS bucket.
        echo "install-hurl: Installing hurl from ${hurl_gcs_url} ... "
        FORCE_USE_CREDENTIAL=true download-or-bust "${hurl_hash}" "${hurl_gcs_url}"
        if [[ -f "${KUBE_HOME}/${hurl_bin}" ]]; then
          chmod a+x ${KUBE_HOME}/${hurl_bin}
          mv "${KUBE_HOME}/${hurl_bin}" "${KUBE_BIN}/${hurl_bin}"
          echo "install-hurl: hurl installed to ${KUBE_BIN}/${hurl_bin}"
          record-preload-info "${hurl_bin}" "${hurl_preload_digest}"
          return
        fi
      }

      function install-k8s-pki {
          local -r k8s_pki_url="${STORAGE_ENDPOINT}/${K8S_PKI_GCS_PATH}"
          local -r k8s_pki_hash="${K8S_PKI_HASH}"

          if is-preloaded "k8s_pki" "${k8s_pki_hash}"; then
            echo "k8s_pki is preloaded"
            return
          fi

          echo "Downloading k8s_pki binary"
          download-or-bust "${k8s_pki_hash}" "${k8s_pki_url}"
          mv "${KUBE_HOME}/k8s_pki" "${KUBE_BIN}/k8s_pki"
          chmod a+x "${KUBE_BIN}/k8s_pki"

          echo "Record k8s_pki preload info"
          record-preload-info "k8s_pki" "${k8s_pki_hash}"
      }


      function install-auger {
        echo "Downloading auger binary"
        if [[ -f "${KUBE_HOME}/bin/auger" ]]; then
          echo "auger is already installed"
          return
        fi
        AUGER_STORE_PATH="${AUGER_STORE_PATH:-${STORAGE_ENDPOINT}/gke-release-staging/auger}"
        AUGER_VERSION="${AUGER_VERSION:-v1.0.0-gke.1}"
        download-or-bust "" "${AUGER_STORE_PATH}/${AUGER_VERSION}/auger.sha1"
        sha1="$(cat auger.sha1)"
        readonly sha1 # Declare readonly separately to avoid masking error values.
        rm -f "auger.sha1"
        download-or-bust "${sha1}" "${AUGER_STORE_PATH}/${AUGER_VERSION}/auger"
        mv "${KUBE_HOME}/auger" "${KUBE_HOME}/bin/auger"
        chmod a+x "${KUBE_HOME}/bin/auger"
        record-preload-info "auger" "${sha1}"
      }

      # Extract etcdctl binary from etcd image.
      function install-etcdctl {
        echo "Installing etcdctl binary"
        if [[ -f "${KUBE_HOME}/bin/etcdctl" ]]; then
          echo "etcdctl is already installed"
          return
        fi
        local -r etcd_image="gcr.io/gke-master-images/etcd:${ETCDCTL_VERSION}"
        container_id="$(docker create "${etcd_image}" sh)"
        readonly containerId
        docker cp "${container_id}:usr/local/bin/etcdctl" "${KUBE_HOME}/bin/etcdctl"
        chmod a+x "${KUBE_HOME}/bin/etcdctl"
        docker rm "${container_id}"
        docker rmi "${etcd_image}"
      }

      function install-gcfsd {
        echo "Downloading Riptide FUSE client"
        if is-preloaded "gcfsd" "${RIPTIDE_FUSE_VERSION}"; then
          echo "gcfsd is preloaded."
          return
        fi

        if [[ "${HOST_ARCH}" == "arm64" ]]; then
          RIPTIDE_FUSE_STORE_PATH="${STORAGE_ENDPOINT}/gke-release/gcfsd/${RIPTIDE_FUSE_VERSION}/arm64"
          TAR_SHA="${RIPTIDE_FUSE_ARM64_SHA512}"
          BIN_SHA="${RIPTIDE_FUSE_BIN_ARM64_SHA512}"
        else
          RIPTIDE_FUSE_STORE_PATH="${STORAGE_ENDPOINT}/gke-release/gcfsd/${RIPTIDE_FUSE_VERSION}"
          TAR_SHA="${RIPTIDE_FUSE_AMD64_SHA512}"
          BIN_SHA="${RIPTIDE_FUSE_BIN_AMD64_SHA512}"
        fi

        echo "Downloading tarball for gcfsd"
        download-or-bust "${TAR_SHA}" "${RIPTIDE_FUSE_STORE_PATH}/gcfsd.tar.gz"

        download-or-bust "${BIN_SHA}" "${RIPTIDE_FUSE_STORE_PATH}/gcfsd"
        mv "${KUBE_HOME}/gcfsd" "${KUBE_HOME}/bin/gcfsd"
        chmod a+x "${KUBE_HOME}/bin/gcfsd"
        record-preload-info "gcfsd" "${RIPTIDE_FUSE_VERSION}"
      }

      function install-riptide-snapshotter {
        echo "Downloading Riptide snapshotter"
        if is-preloaded "containerd-gcfs-grpc" "${RIPTIDE_SNAPSHOTTER_VERSION}"; then
          echo "containerd-gcfs-grpc is preloaded."
          return
        fi
        RIPTIDE_SNAPSHOTTER_STORE_PATH="${STORAGE_ENDPOINT}/gke-release/gcfs-snapshotter/${RIPTIDE_SNAPSHOTTER_VERSION}"

        echo "Downloading tarball for riptide-snapshotter"
        download-or-bust "${RIPTIDE_SNAPSHOTTER_SHA512}" "${RIPTIDE_SNAPSHOTTER_STORE_PATH}/containerd-gcfs-grpc.tar.gz"

        if [[ "${HOST_ARCH}" == "arm64" ]]; then
          RIPTIDE_SNAPSHOTTER_BINARY="containerd-gcfs-grpc-arm64"
          RIPTIDE_SNAPSHOTTER_BIN_SHA512="${RIPTIDE_SNAPSHOTTER_BIN_ARM64_SHA512}"
        else
          RIPTIDE_SNAPSHOTTER_BINARY="containerd-gcfs-grpc"
          RIPTIDE_SNAPSHOTTER_BIN_SHA512="${RIPTIDE_SNAPSHOTTER_BIN_AMD64_SHA512}"
        fi

        download-or-bust "${RIPTIDE_SNAPSHOTTER_BIN_SHA512}" "${RIPTIDE_SNAPSHOTTER_STORE_PATH}/${RIPTIDE_SNAPSHOTTER_BINARY}"
        mv "${KUBE_HOME}/${RIPTIDE_SNAPSHOTTER_BINARY}" "${KUBE_HOME}/bin/containerd-gcfs-grpc"
        chmod a+x "${KUBE_HOME}/bin/containerd-gcfs-grpc"
        record-preload-info "containerd-gcfs-grpc" "${RIPTIDE_SNAPSHOTTER_VERSION}"
      }

      # Install Riptide FUSE client and Riptide snapshotter
      function install-riptide {
        install-gcfsd
        install-riptide-snapshotter
      }

      function prepare-riptide-snapshotter-preloader {
        source ${KUBE_BIN}/gke-internal-configure-helper.sh
        log-wrap 'GKESetupContainerd' gke-setup-containerd
      }

      function install-auth-provider-gcp {
        case "${HOST_ARCH}" in
          amd64)
            local -r auth_provider_gcp_hash="${AUTH_PROVIDER_GCP_HASH_LINUX_AMD64}"
            ;;
          arm64)
            local -r auth_provider_gcp_hash="${AUTH_PROVIDER_GCP_HASH_LINUX_ARM64}"
            ;;
          *)
            echo "Unrecognized version and platform/arch combination: ${HOST_PLATFORM}/${HOST_ARCH}"
            exit 1
        esac

        if is-preloaded "auth-provider-gcp" "${auth_provider_gcp_hash}"; then
          echo "auth-provider-gcp is preloaded."
          return
        fi

        local -r auth_provider_storage_url="${STORAGE_ENDPOINT}/gke-release/auth-provider-gcp/${AUTH_PROVIDER_GCP_VERSION}/${HOST_PLATFORM}_${HOST_ARCH}/auth-provider-gcp"
        echo "Downloading auth-provider-gcp ${auth_provider_storage_url}" .
        download-or-bust "${auth_provider_gcp_hash}" "${auth_provider_storage_url}"

        # Keep in sync with --image-credential-provider-bin-dir in cloud/kubernetes/distro/legacy/kube_env.go
        mv "${KUBE_HOME}/auth-provider-gcp" "${KUBE_BIN}"
        chmod a+x "${KUBE_BIN}/auth-provider-gcp"

        record-preload-info "auth-provider-gcp" "${auth_provider_gcp_hash}"
      }

      function download-gvisor-installer {
        local -r installer_image_hash=$1
        local -r installer_image="${KUBE_DOCKER_REGISTRY}/gke-gvisor-installer@sha256:${installer_image_hash}"
        if access_token=$(get-credentials); then
          "${KUBE_BIN}/crictl" pull --creds "oauth2accesstoken:${access_token}" "${installer_image}"
        else
          "${KUBE_BIN}/crictl" pull "${installer_image}"
        fi
      }

      function configure-cgroup-mode {
        if which cgroup_helper > /dev/null 2>&1; then
          if [[ "${CGROUP_MODE:-}" == "v1" ]] && cgroup_helper show | grep -q 'unified'; then
            cgroup_helper set hybrid
            echo "set cgroup config to hybrid, now rebooting..."
            reboot
          elif [[ "${CGROUP_MODE:-}" == "v2" ]] && cgroup_helper show | grep -q 'hybrid'; then
            cgroup_helper set unified
            echo "set cgroup config to unified, now rebooting..."
            reboot
          fi
        fi
      }

      # To improve the shieded VM reliability b/327650100
      function check-tpm-file {
        if [[ -z "${TPM_BOOTSTRAP_KEY:-}" ]]; then
          echo "TPM_BOOTSTRAP_KEY is empty, thus vTPM is disabled, skip tpm file check"
          return 0
        else
          echo "TPM_BOOTSTRAP_KEY is not empty, thus vTPM is enabled, checking tpm file"
          if [[ -e "/dev/tpm0" ]]; then
            echo "/dev/tpm0 exists."
            return 0
          else
            echo "/dev/tpm0 doesn't exist."
            return 1
          fi
        fi
      }

      function detect-reboot-needed {
        # Exit if it is on the master
        if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
          return
        fi

        if [[ "${ENABLE_BEST_EFFORT_NODE_REBOOT:-}" == "true" ]]; then
          if check-tpm-file; then
            echo "TPM is present; continuing bootstrap..."
            return
          fi

          echo "TPM file check doesn't pass!"
          if ! REBOOT_HISTORY=$(journalctl --list-boots --quiet | wc -l); then
            echo "skip reboot attempt due to the journalctl error"
            return
          fi
          if [[ $(($REBOOT_HISTORY)) -gt ${MAX_BOOT_COUNT} ]]; then
            echo "best effort reboot attempt ${REBOOT_HISTORY} exceed ${MAX_BOOT_COUNT}! stop rebooting!"
          else
            # write to a persistent file after reboot for NPD reporting event
            # used in npd-custom-plugins/configs/node-reboot-monitor.json
            mkdir -p /var/lib/gke
            echo '1' >> /var/lib/gke/best_effort_reboot_marker
            echo "best effort reboot attempt ${REBOOT_HISTORY}! rebooting..."
            reboot
          fi
        fi
      }

      # A helper function for loading a docker image. It keeps trying up to 5 times.
      #
      # $1: Full path of the docker image
      function try-load-docker-image {
        local -r img=$1
        echo "Try to load docker image file ${img}"
        # Temporarily turn off errexit, because we don't want to exit on first failure.
        set +e
        local -r max_attempts=5
        local -i attempt_num=1

        if [[ "${CONTAINER_RUNTIME_NAME:-}" == "containerd" || "${CONTAINERD_TEST:-}"  == "containerd" ]]; then
          load_image_command=${LOAD_IMAGE_COMMAND:-ctr -n=k8s.io images import}
        else
          load_image_command="${LOAD_IMAGE_COMMAND:-}"
        fi

        # Deliberately word split load_image_command
        # shellcheck disable=SC2086
        until timeout 30 ${load_image_command} "${img}"; do
          if [[ "${attempt_num}" == "${max_attempts}" ]]; then
            echo "Fail to load docker image file ${img} using ${load_image_command} after ${max_attempts} retries. Exit!!"
            exit 1
          else
            attempt_num=$((attempt_num+1))
            sleep 5
          fi
        done
        # Re-enable errexit.
        set -e
      }

      # Loads kube-system docker images. It is better to do it before starting kubelet,
      # as kubelet will restart docker daemon, which may interfere with loading images.
      function load-docker-images {
        echo "Start loading kube-system docker images"
        local -r img_dir="${KUBE_HOME}/kube-docker-files"
        if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
          try-load-docker-image "${img_dir}/kube-apiserver.tar"
          try-load-docker-image "${img_dir}/kube-controller-manager.tar"
          try-load-docker-image "${img_dir}/kube-scheduler.tar"
        else
          try-load-docker-image "${img_dir}/kube-proxy.tar"
        fi
      }

      # A helper function for retagging a docker image with new tag and new registry.
      # $1: Image prefix
      # $2: Image tag
      # $3: Destination tag
      # $4: Destination registry
      function retag-docker-image {
        local -r img_prefix=$1
        local -r img_tag=$2
        local -r dest_tag=$3
        local -r dest_registry=$4
        echo "Retagging all images with prefix: ${img_prefix} and tag: ${img_tag} with new tag: ${dest_tag} and new registry: ${dest_registry}"
        local src_img=""
        for src_img in $(ctr -n=k8s.io images list -q | grep "/${img_prefix}" | grep ":${img_tag}$"); do
          dest_img=${src_img/:${img_tag}/:${dest_tag}}
          dest_img=${dest_registry}/${dest_img##*/}
          if [[ "${dest_img}" != "${src_img}" ]]; then
            cmd="ctr -n=k8s.io image tag --force ${src_img} ${dest_img}"
            echo "Retag command: ${cmd}"
            ${cmd}
          fi
        done
      }

      # Retags kube-system docker images with passed in kube-apiserver/kubelet versions.
      function retag-docker-images {
        echo "Start retagging kube-system docker images"
        local src_tag=""
        local dest_tag=""
        if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
          src_tag=$(cat /home/kubernetes/kube-docker-files/kube-apiserver.docker_tag)
          # Keep the tag the same unless overridden
          dest_tag="${src_tag}"
          if [[ -n "${KUBE_APISERVER_VERSION:-}" ]]; then
            # Docker tags cannot contain '+', make CI versions a valid docker tag.
            dest_tag=${KUBE_APISERVER_VERSION/+/_}
          fi
          retag-docker-image "kube-apiserver" "${src_tag}" "${dest_tag}" "${KUBE_DOCKER_REGISTRY}"
          retag-docker-image "kube-controller-manager" "${src_tag}" "${dest_tag}" "${KUBE_DOCKER_REGISTRY}"
          retag-docker-image "kube-scheduler" "${src_tag}" "${dest_tag}" "${KUBE_DOCKER_REGISTRY}"
        else
          src_tag=$(cat /home/kubernetes/kube-docker-files/kube-proxy.docker_tag)
          # Keep the tag the same unless overridden
          dest_tag="${src_tag}"
          if [[ -n "${KUBELET_VERSION:-}" ]]; then
            # Docker tags cannot contain '+', make CI versions a valid docker tag.
            dest_tag=${KUBELET_VERSION/+/_}
          fi
          retag-docker-image "kube-proxy" "${src_tag}" "${dest_tag}" "${KUBE_DOCKER_REGISTRY}"
        fi
      }

      function ensure-container-runtime {
        if [[ "${CONTAINER_RUNTIME}" == "docker" ]]; then
          echo "Dockershim is not supported. Container runtime must be set to containerd"
          exit 2
        fi
      }

      function pin-docker-image {
        local -r img_prefix=$1
        echo "Pinning: ${img_prefix}"
        for img in $(ctr -n=k8s.io images list -q | grep "/${img_prefix}"); do
          cmd="ctr -n k8s.io images label ${img} io.cri-containerd.pinned=pinned"
          ${cmd}
        done
      }

      function pin-docker-images {
        if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
          pin-docker-image "kube-apiserver"
          pin-docker-image "kube-controller-manager"
          pin-docker-image "kube-scheduler"
        else
          pin-docker-image "kube-proxy"
        fi
      }

      # Downloads kubernetes binaries and kube-system manifest tarball, unpacks them,
      # and places them into suitable directories. Files are placed in /home/kubernetes.
      function install-kube-binary-config {
        cd "${KUBE_HOME}"
        local server_binary_tar_urls
        while IFS= read -r url; do
          server_binary_tar_urls+=("$url")
        done < <(split-commas "${SERVER_BINARY_TAR_URL}")
        local -r server_binary_tar="${server_binary_tar_urls[0]##*/}"
        if [[ -n "${SERVER_BINARY_TAR_HASH:-}" ]]; then
          local -r server_binary_tar_hash="${SERVER_BINARY_TAR_HASH}"
        else
          echo "Downloading binary release sha512 (not found in env)"
          download-or-bust "" "${server_binary_tar_urls[@]/.tar.gz/.tar.gz.sha512}"
          local -r server_binary_tar_hash=$(cat "${server_binary_tar}.sha512")
        fi

        if is-preloaded "${server_binary_tar}" "${server_binary_tar_hash}"; then
          echo "${server_binary_tar} is preloaded."
        else
          echo "Downloading binary release tar"
          download-or-bust "${server_binary_tar_hash}" "${server_binary_tar_urls[@]}"
          tar xzf "${KUBE_HOME}/${server_binary_tar}" -C "${KUBE_HOME}" --overwrite
          # Copy docker_tag and image files to ${KUBE_HOME}/kube-docker-files.
          local -r src_dir="${KUBE_HOME}/kubernetes/server/bin"
          local dst_dir="${KUBE_HOME}/kube-docker-files"
          mkdir -p "${dst_dir}"
          cp "${src_dir}/"*.docker_tag "${dst_dir}"
          if [[ "${KUBERNETES_MASTER:-}" == "false" ]]; then
            cp "${src_dir}/kube-proxy.tar" "${dst_dir}"
          else
            cp "${src_dir}/kube-apiserver.tar" "${dst_dir}"
            cp "${src_dir}/kube-controller-manager.tar" "${dst_dir}"
            cp "${src_dir}/kube-scheduler.tar" "${dst_dir}"
            cp -r "${KUBE_HOME}/kubernetes/addons" "${dst_dir}"
          fi
          load-docker-images
          mv "${src_dir}/kubelet" "${KUBE_BIN}"
          mv "${src_dir}/kubectl" "${KUBE_BIN}"

          # Some older images have LICENSES baked-in as a file. Presumably they will
          # have the directory baked-in eventually.
          rm -rf "${KUBE_HOME}"/LICENSES
          mv "${KUBE_HOME}/kubernetes/LICENSES" "${KUBE_HOME}"
          mv "${KUBE_HOME}/kubernetes/kubernetes-src.tar.gz" "${KUBE_HOME}"

          # Pin docker images to avoid GC
          pin-docker-images

          record-preload-info "${server_binary_tar}" "${server_binary_tar_hash}"
        fi

        retag-docker-images

        if [[ "${NETWORK_PROVIDER:-}" == "kubenet" ]] || \
           [[ "${NETWORK_PROVIDER:-}" == "cni" ]]; then
          install-cni-binaries
        fi

        # Put kube-system pods manifests in ${KUBE_HOME}/kube-manifests/.
        install-kube-manifests
        chmod -R 755 "${KUBE_BIN}"

        # Install gci mounter related artifacts to allow mounting storage volumes in GCI
        install-gci-mounter-tools

        # Remount the Flexvolume directory with the "exec" option, if needed.
        if [[ "${REMOUNT_VOLUME_PLUGIN_DIR:-}" == "true" && -n "${VOLUME_PLUGIN_DIR:-}" ]]; then
          remount-flexvolume-directory "${VOLUME_PLUGIN_DIR}"
        fi

        # Install crictl on each node.
        install-crictl

        # Preload pause image
        preload-pause-image

        # Copy health check binaries to a tmpfs mount to reduce block IO usage.
        setup-shm-healthcheck-binaries

        # TODO(awly): include the binary and license in the OS image.
        install-exec-auth-plugin

        if [[ "${KUBERNETES_MASTER:-}" == "false" ]] && \
           [[ "${ENABLE_NODE_PROBLEM_DETECTOR:-}" == "standalone" ]]; then
          install-node-problem-detector
          install-npd-custom-plugins
        fi

        # Clean up.
        rm -rf "${KUBE_HOME}/kubernetes"
        rm -f "${KUBE_HOME}/${server_binary_tar}"
        rm -f "${KUBE_HOME}/${server_binary_tar}.sha512"
      }

      function setup-shm-healthcheck-binaries() {
        if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
          return
        fi
        if [[ "${ENABLE_SHM_HEALTHCHECK_BINARIES:-}" != "true" ]];then
          return
        fi

        local -r shm_dir="${HEALTHCHECK_SHM_DIR:-/dev/kube_shm}"
        local -r shm_bin_dir="${shm_dir}/bin"

        mkdir -p "$shm_dir"
        mount -t tmpfs -o exec none "$shm_dir"
        mkdir "${shm_bin_dir}"

        cp -f "${KUBE_BIN}/crictl" "${shm_bin_dir}/crictl"
        cp -f "$(which curl)" "${shm_bin_dir}/curl"
      }

      function configure-pga-if-needed() {
        echo "Detecting connectivity to ${STORAGE_ENDPOINT}..."
        local status=0
        curl --ipv4 -L --connect-timeout 10 --retry 3  --retry-connrefused ${STORAGE_ENDPOINT} || status="$?"
        # connection is refused(7) or timeout(28).
        if [[ "${status}" == "7" || "${status}" == "28" ]]; then
          status=0
          local pga_ip
          pga_ip=`curl ${PGA_ENDPOINT} -w '%{remote_ip}' --connect-timeout 10 -s -o /dev/null` || status="$?"
          registry_domain="$(echo "${KUBE_DOCKER_REGISTRY}" | cut -d '/' -f 1)"
          if [[ "${status}" == "0" ]]; then
            echo "Configure /etc/hosts to use private google access"
            echo "$pga_ip ${STORAGE_ENDPOINT#https://}" >> /etc/hosts
            echo "$pga_ip ${registry_domain}" >> /etc/hosts
            # continue pga support for domain gke.gcr.io
            echo "$pga_ip gke.gcr.io" >> /etc/hosts
          fi
        fi
      }

      # This function detects the platform/arch of the machine where the script runs,
      # and sets the HOST_PLATFORM and HOST_ARCH environment variables accordingly.
      # Callers can specify HOST_PLATFORM_OVERRIDE and HOST_ARCH_OVERRIDE to skip the detection.
      # This function is adapted from the detect_client_info function in cluster/get-kube-binaries.sh
      # and kube::util::host_os, kube::util::host_arch functions in hack/lib/util.sh
      # This function should be synced with detect_host_info in ./configure-helper.sh
      function detect_host_info() {
        HOST_PLATFORM=${HOST_PLATFORM_OVERRIDE:-"$(uname -s)"}
        case "${HOST_PLATFORM}" in
          Linux|linux)
            HOST_PLATFORM="linux"
            ;;
          *)
            echo "Unknown, unsupported platform: ${HOST_PLATFORM}." >&2
            echo "Supported platform(s): linux." >&2
            echo "Bailing out." >&2
            exit 2
        esac

        HOST_ARCH=${HOST_ARCH_OVERRIDE:-"$(uname -m)"}
        case "${HOST_ARCH}" in
          x86_64*|i?86_64*|amd64*)
            HOST_ARCH="amd64"
            ;;
          aHOST_arch64*|aarch64*|arm64*)
            HOST_ARCH="arm64"
            ;;
          *)
            echo "Unknown, unsupported architecture (${HOST_ARCH})." >&2
            echo "Supported architecture(s): amd64 and arm64." >&2
            echo "Bailing out." >&2
            exit 2
            ;;
        esac
      }

      # Retries a command forever with a delay between retries.
      # Args:
      #  $1    : delay between retries, in seconds.
      #  $2... : the command to run.
      function retry-forever {
        local -r delay="$1"
        shift 1

        until "$@"; do
          echo "== $* failed, retrying after ${delay}s"
          sleep "${delay}"
        done
      }

      # Initializes variables used by the log-* functions.
      #
      # get-metadata-value must be defined before calling this function.
      #
      # NOTE: this function is duplicated in configure-helper.sh, any changes here
      # should be duplicated there as well.
      function log-init {
        # Used by log-* functions.
        LOG_CLUSTER_ID=${LOG_CLUSTER_ID:-$(get-metadata-value 'instance/attributes/cluster-uid' 'get-metadata-value-error')}
        LOG_INSTANCE_NAME=$(hostname || echo 'hostname-error')
        LOG_BOOT_ID=$(journalctl --list-boots | grep -E '^ *0' | awk '{print $2}' || echo 'journalctl-error')
        declare -Ag LOG_START_TIMES
        declare -ag LOG_TRAP_STACK

        LOG_STATUS_STARTED='STARTED'
        LOG_STATUS_COMPLETED='COMPLETED'
        LOG_STATUS_ERROR='ERROR'
      }

      # Sets an EXIT trap.
      # Args:
      #   $1:... : the trap command.
      #
      # NOTE: this function is duplicated in configure-helper.sh, any changes here
      # should be duplicated there as well.
      function log-trap-push {
        local t="${*:1}"
        LOG_TRAP_STACK+=("${t}")
        # shellcheck disable=2064
        trap "${t}" EXIT
      }

      # Removes and restores an EXIT trap.
      #
      # NOTE: this function is duplicated in configure-helper.sh, any changes here
      # should be duplicated there as well.
      function log-trap-pop {
        # Remove current trap.
        unset 'LOG_TRAP_STACK[-1]'

        # Restore previous trap.
        if [ ${#LOG_TRAP_STACK[@]} -ne 0 ]; then
          local t="${LOG_TRAP_STACK[-1]}"
          # shellcheck disable=2064
          trap "${t}" EXIT
        else
          # If no traps in stack, clear.
          trap EXIT
        fi
      }

      # Logs the end of a bootstrap step that errored.
      # Args:
      #  $1 : bootstrap step name.
      #
      # NOTE: this function is duplicated in configure-helper.sh, any changes here
      # should be duplicated there as well.
      function log-error {
        local bootstep="$1"

        log-proto "${bootstep}" "${LOG_STATUS_ERROR}" "encountered non-zero exit code"
      }

      # Wraps a command with bootstrap logging.
      # Args:
      #   $1    : bootstrap step name.
      #   $2... : the command to run.
      #
      # NOTE: this function is duplicated in configure-helper.sh, any changes here
      # should be duplicated there as well.
      function log-wrap {
        local bootstep="$1"
        local command="${*:2}"

        log-trap-push "log-error ${bootstep}"
        log-proto "${bootstep}" "${LOG_STATUS_STARTED}"
        $command
        log-proto "${bootstep}" "${LOG_STATUS_COMPLETED}"
        log-trap-pop
      }

      # Logs a bootstrap step start. Prefer log-wrap.
      # Args:
      #   $1 : bootstrap step name.
      #
      # NOTE: this function is duplicated in configure-helper.sh, any changes here
      # should be duplicated there as well.
      function log-start {
        local bootstep="$1"

        log-trap-push "log-error ${bootstep}"
        log-proto "${bootstep}" "${LOG_STATUS_STARTED}"
      }

      # Logs a bootstrap step end. Prefer log-wrap.
      # Args:
      #   $1 : bootstrap step name.
      #
      # NOTE: this function is duplicated in configure-helper.sh, any changes here
      # should be duplicated there as well.
      function log-end {
        local bootstep="$1"

        log-proto "${bootstep}" "${LOG_STATUS_COMPLETED}"
        log-trap-pop
      }

      # Writes a log proto to stdout.
      # Args:
      #   $1: bootstrap step name.
      #   $2: status. Either 'STARTED', 'COMPLETED', or 'ERROR'.
      #   $3: optional status reason.
      #
      # NOTE: this function is duplicated in configure-helper.sh, any changes here
      # should be duplicated there as well.
      function log-proto {
        local bootstep="$1"
        local status="$2"
        local status_reason="${3:-}"

        # Get current time.
        local current_time
        current_time="$(date --utc '+%s.%N')"
        # ...formatted as UTC RFC 3339.
        local timestamp
        timestamp="$(date --utc --date="@${current_time}" '+%FT%T.%NZ')"

        # Calculate latency.
        local latency='null'
        if [ "${status}" == "${LOG_STATUS_STARTED}" ]; then
          LOG_START_TIMES["${bootstep}"]="${current_time}"
        else
          local start_time="${LOG_START_TIMES["${bootstep}"]}"
          unset 'LOG_START_TIMES['"${bootstep}"']'

          # Bash cannot do non-integer math, shell out to awk.
          latency="$(echo "${current_time} ${start_time}" | awk '{print $1 - $2}')s"

          # The default latency is null which cannot be wrapped as a string so we must
          # do it here instead of the printf.
          latency="\"${latency}\""
        fi

        printf '[cloud.kubernetes.monitoring.proto.SerialportLog] {"cluster_hash":"%s","vm_instance_name":"%s","boot_id":"%s","timestamp":"%s","bootstrap_status":{"step_name":"%s","status":"%s","status_reason":"%s","latency":%s}}\n' \
        "${LOG_CLUSTER_ID}" "${LOG_INSTANCE_NAME}" "${LOG_BOOT_ID}" "${timestamp}" "${bootstep}" "${status}" "${status_reason}" "${latency}"
      }

      # Prelaod components for both - preloader and runtime
      # Variables needed for this function to work will be set by the preloader
      function preload {
        cd "${KUBE_HOME}"
        if [[ "${ENABLE_AUTH_PROVIDER_GCP:-""}" == "true" ]]; then
          log-wrap 'InstallExternalCredentialProvider' install-auth-provider-gcp
        fi

        if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
          log-wrap 'InstallHurl' install-hurl
        fi

        if [[ "${KUBERNETES_MASTER:-}" == "true" && -n "${K8S_PKI_GCS_PATH:-}" ]]; then
          log-wrap "InstallK8sPki" install-k8s-pki
        fi

        if [[ "${KUBERNETES_MASTER:-}" != "true" && -n "${GVISOR_INSTALLER_IMAGE_HASH:-}" ]]; then
          log-wrap 'DownloadGvisorInstaller' download-gvisor-installer "${GVISOR_INSTALLER_IMAGE_HASH}"
        fi
      }

      ######### Main Function ##########
      log-init
      detect_host_info

      # Preloader will source this script, and skip the main function. The preloader
      # will choose what to preload by calling install-X functions directly.
      # When configure.sh is sourced by the preload script, $0 and $BASH_SOURCE are
      # different. $BASH_SOURCE still contains the path of configure.sh, while $0 is
      # the path of the preload script.
      if [[ "$0" != "$BASH_SOURCE" && "${IS_PRELOADER:-"false"}" == "true" ]]; then
        # preload common components
        preload
        echo "Running in preloader instead of VM bootsrapping. Skipping installation steps as preloader script will source configure.sh and call all non-common functions."
        return
      fi

      log-start 'ConfigureMain'
      echo "Start to install kubernetes files"

      # if install fails, message-of-the-day (motd) will warn at login shell
      log-wrap 'SetBrokenMotd' set-broken-motd

      KUBE_HOME="/home/kubernetes"
      KUBE_BIN="${KUBE_HOME}/bin"

      if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
        if [[ "${IS_PRELOADER:-}" != "true" ]] &&\
           grep -qs "PRELOADED," "${KUBE_HOME}/preload_info" &&\
           [[ $(get-metadata-value "instance/attributes/fail-on-artifact-mismatch" "false") == "true" ]]; then
             # Disallow artifact downloads when:
             # - running on master VMs
             # - && not in preloader (running in bootstrap)
             # - && VM image is preloaded
             # - && failure on artifact mismatch feature is enabled
             ARTIFACT_DOWNLOAD_RESTRICTED="true"
        fi

        log-wrap 'InstallHurl' install-hurl
      fi

      # download and source kube-env
      log-wrap 'DownloadKubeEnv' download-kube-env
      log-wrap 'SourceKubeEnv' source "${KUBE_HOME}/kube-env"

      if [[ "${CONFIGURE_PGA}" == "true" ]]; then
        configure-pga-if-needed
      fi

      log-wrap 'ConfigureCgroupMode' configure-cgroup-mode

      log-wrap 'BestEffortRebootDetection' detect-reboot-needed

      log-wrap 'DownloadKubeletConfig' download-kubelet-config "${KUBE_HOME}/kubelet-config.yaml"

      if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
        log-wrap 'DownloadKubeMasterCerts' download-kube-master-certs-hurl
      fi

      if docker-installed; then
        # We still need to configure docker so it wouldn't reserver the 172.17.0/16 subnet
        # And if somebody will start docker to build or pull something, logging will also be set up
        log-wrap 'AssembleDockerFlags' assemble-docker-flags
      fi

      # preload common components
      preload

      # ensure chosen container runtime is present
      log-wrap 'EnsureContainerRuntime' ensure-container-runtime

      # binaries and kube-system manifests
      log-wrap 'InstallKubeBinaryConfig' install-kube-binary-config

      # install Riptide components on non-Ubuntu nodes
      if ! is-ubuntu && [[ "${KUBERNETES_MASTER:-}" != "true" ]]; then
        log-wrap 'InstallRiptide' install-riptide
      fi

      echo "Done for installing kubernetes files"
      log-end 'ConfigureMain'


      (
      (
        set +e



        echo "downloading castai-node-logs-sender binary from https://storage.googleapis.com/castai-node-components/castai-node-logs-sender/releases/0.12.0/castai-node-logs-sender-linux-amd64.tar.gz" >> logs_sender_download_output.log
        curl --fail --silent --show-error --max-time 120 --retry 3 --retry-delay 5 --retry-connrefused https://storage.googleapis.com/castai-node-components/castai-node-logs-sender/releases/0.12.0/castai-node-logs-sender-linux-amd64.tar.gz -o castai-node-logs-sender-linux-amd64.tar.gz 2>> logs_sender_download_output.log
        DOWNLOAD_ERROR=$?

        if [ $DOWNLOAD_ERROR -eq 0 ]; then
          echo "downloading castai-node-logs-sender succeeded" >> logs_sender_download_output.log
          echo "c8941537cdba875abd5bfabefc3878d3fd9cfc7b2b665161bd348e2f846c2619 castai-node-logs-sender-linux-amd64.tar.gz" | sha256sum --check --status 2>> logs_sender_download_output.log
        else
          echo "downloading castai-node-logs-sender failed with error $DOWNLOAD_ERROR" >> logs_sender_download_output.log
        fi

        TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%S.%3NZ")
        PREPEND_STRING="{\"logEvents\":[{\"level\": \"info\",\"time\":\"$TIMESTAMP\",\"message\":\""
        CONTENT_STRING=$(awk 1 ORS='\\n' logs_sender_download_output.log)
        APPEND_STRING="\"}]}"

        printf "%s%s%s" "$PREPEND_STRING" "$CONTENT_STRING" "$APPEND_STRING" > logs_sender_download_output.json

        curl --fail --silent --show-error --max-time 120 --retry 3 --retry-delay 5 --retry-connrefused -X POST "https://api--damians-macbook-pro.local.cast.ai/v1/kubernetes/external-clusters/0b3bc1eb-70da-4cde-96af-f672f80dfcc6/nodes/4a209c2c-28d3-471e-9312-9d207a6e2dd2/logs" -H "X-Api-Key: 220389b723c8b5092eb1885ef5f5bb8746a395e22bc20b2908e83ff4c51c3fc7" --data-binary "$(cat logs_sender_download_output.json)" 2> /dev/null
      )

      mkdir -p bin
      BIN_PATH=$PWD/bin/castai-node-logs-sender
      tar -xvzf castai-node-logs-sender-linux-amd64.tar.gz
      rm castai-node-logs-sender-linux-amd64.tar.gz
      mv castai-node-logs-sender $BIN_PATH
      chmod +x $BIN_PATH

      CONF_PATH=/etc/systemd/system/castai-node-logs-sender.conf

      # Proxy vars (if present) below don't have prefix since we want http libraries to pick them automatically in the binary.
      cat >${CONF_PATH} <<EOL
      CASTAI_API_URL="https://api--damians-macbook-pro.local.cast.ai"
      CASTAI_API_KEY="220389b723c8b5092eb1885ef5f5bb8746a395e22bc20b2908e83ff4c51c3fc7"
      CASTAI_CLUSTER_ID="0b3bc1eb-70da-4cde-96af-f672f80dfcc6"
      CASTAI_NODE_ID="4a209c2c-28d3-471e-9312-9d207a6e2dd2"
      CASTAI_PROVIDER="gke"

      EOL

      echo "# Creating castai-node-logs-sender systemd service"

      cat >/etc/systemd/system/castai-node-logs-sender.service <<EOL
      [Unit]
      Description=CAST.AI service to send node init logs for troubleshooting.
      After=network.target

      [Service]
      Type=simple
      EnvironmentFile=${CONF_PATH}
      ExecStart=${BIN_PATH}
      RemainAfterExit=false
      StandardOutput=journal

      [Install]
      WantedBy=multi-user.target
      EOL

      echo "# Starting castai-node-logs-sender service..."

      systemctl --now enable castai-node-logs-sender
      ) &


      echo "# Overriding kubelet certificate directory mount"
      sed -i 's, echo "Mounting /var/lib/kubelet/pki on tmpfs",#&,' /home/kubernetes/bin/configure-helper.sh
      sed -i 's, mount -t tmpfs tmpfs /var/lib/kubelet/pki,#&,' /home/kubernetes/bin/configure-helper.sh
  - key: user-data
    value: |
      #cloud-config

      users:
        - name: kube-bootstrap-logs-forwarder
          gecos: User the kube-bootstrap-logs-forwarder.service runs as.
          system: true
          shell: /sbin/nologin

      write_files:
        - path: /etc/systemd/system/kube-bootstrap-logs-forwarder.service
          permissions: '0644'
          owner: root
          content: |
            [Unit]
            Description=Forwards Kubernetes bootstrap logs to serial port.
            Before=setup-kubernetes-dir.service

            [Service]
            User=kube-bootstrap-logs-forwarder
            Group=systemd-journal
            SupplementaryGroups=serial
            ExecStart=journalctl --no-tail --no-pager --follow --utc --output short-iso --unit setup-kubernetes-dir --unit placeholders-presuspend-setup --unit kube-node-installation --unit kube-node-configuration --unit kubelet
            StandardOutput=tty
            TTYPath=/dev/ttyS2

            [Install]
            WantedBy=kubernetes.target

        - path: /etc/systemd/system/setup-kubernetes-dir.service
          permissions: 0644
          owner: root
          content: |
            [Unit]
            Description=Sets up required directories and mounts.
            After=network-online.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStart=/bin/mkdir -p /home/kubernetes/bin
            ExecStart=/bin/mount --bind /home/kubernetes/bin /home/kubernetes/bin
            ExecStart=/bin/mount -o remount,exec /home/kubernetes/bin

            [Install]
            WantedBy=kubernetes.target

        - path: /etc/systemd/system/placeholders-presuspend-setup.service
          permissions: 0644
          owner: root
          content: |
            [Unit]
            Description=Perform required presuspend logic for Placeholders VM, skip for Non-Placeholders VMs.
            After=setup-kubernetes-dir.service

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecCondition=/usr/bin/curl --fail --retry 5 --retry-delay 3 --silent --show-error -H "X-Google-Metadata-Request: True" -o /home/kubernetes/bin/placeholders-presuspend.sh http://metadata.google.internal/computeMetadata/v1/instance/attributes/placeholders-presuspend-sh
            ExecStartPre=/bin/chmod 544 /home/kubernetes/bin/placeholders-presuspend.sh
            ExecStart=/home/kubernetes/bin/placeholders-presuspend.sh

            [Install]
            WantedBy=kubernetes.target


        - path: /etc/systemd/system/kube-node-installation.service
          permissions: '0644'
          owner: root
          content: |
            [Unit]
            Description=Download and install k8s binaries and configurations
            After=placeholders-presuspend-setup.service

            [Service]
            Environment=KUBERNETES_MASTER=false
            Type=oneshot
            RemainAfterExit=yes
            ExecStartPre=/usr/bin/curl --fail --retry 5 --retry-delay 3 --silent --show-error -H "X-Google-Metadata-Request: True" -o /home/kubernetes/bin/configure.sh http://metadata.google.internal/computeMetadata/v1/instance/attributes/configure-sh
            ExecStartPre=/bin/chmod 544 /home/kubernetes/bin/configure.sh
            ExecStart=/home/kubernetes/bin/configure.sh

            [Install]
            WantedBy=kubernetes.target

        - path: /etc/systemd/system/kube-node-configuration.service
          permissions: '0644'
          owner: root
          content: |
            [Unit]
            Description=Configure kubernetes node
            After=kube-node-installation.service

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStartPre=/bin/chmod 544 /home/kubernetes/bin/configure-helper.sh
            ExecStart=/home/kubernetes/bin/configure-helper.sh
            ExecStartPost=systemctl stop kube-bootstrap-logs-forwarder.service

            [Install]
            WantedBy=kubernetes.target

        - path: /etc/systemd/system/kube-container-runtime-monitor.service
          permissions: '0644'
          owner: root
          content: |
            [Unit]
            Description=Kubernetes health monitoring for container runtime
            After=kube-node-configuration.service

            [Service]
            Restart=always
            RestartSec=10
            RemainAfterExit=yes
            RemainAfterExit=yes
            ExecStartPre=/bin/chmod 544 /home/kubernetes/bin/health-monitor.sh
            ExecStart=/home/kubernetes/bin/health-monitor.sh container-runtime

            [Install]
            WantedBy=kubernetes.target

        - path: /etc/systemd/system/kubelet-monitor.service
          permissions: '0644'
          owner: root
          content: |
            [Unit]
            Description=Kubernetes health monitoring for kubelet
            After=kube-node-configuration.service

            [Service]
            Restart=always
            RestartSec=10
            RemainAfterExit=yes
            RemainAfterExit=yes
            ExecStartPre=/bin/chmod 544 /home/kubernetes/bin/health-monitor.sh
            ExecStart=/home/kubernetes/bin/health-monitor.sh kubelet

            [Install]
            WantedBy=kubernetes.target

        - path: /etc/systemd/system/kube-logrotate.timer
          permissions: '0644'
          owner: root
          content: |
            [Unit]
            Description=Hourly kube-logrotate invocation

            [Timer]
            OnCalendar=hourly

            [Install]
            WantedBy=kubernetes.target

        - path: /etc/systemd/system/kube-logrotate.service
          permissions: '0644'
          owner: root
          content: |
            [Unit]
            Description=Kubernetes log rotation
            After=kube-node-configuration.service

            [Service]
            Type=oneshot
            # The relative path is being used as the path is different between image types - for example between Ubuntu and COS. See ExecSearchPath for allowed paths.
            ExecSearchPath=/usr/bin:/usr/sbin
            ExecStart=logrotate /etc/logrotate.conf

            [Install]
            WantedBy=kubernetes.target

        - path: /etc/systemd/system/kubernetes.target
          permissions: '0644'
          owner: root
          content: |
            [Unit]
            Description=Kubernetes

            [Install]
            WantedBy=multi-user.target

        - path: /etc/modprobe.d/sunrpc.conf
          permissions: '0644'
          owner: root
          # The GKE metadata server uses ports 987-989, so the sunrpc range should be restricted to be below.
          content: |
            options sunrpc max_resvport=986

      runcmd:
        - systemctl enable
            kube-bootstrap-logs-forwarder.service
            setup-kubernetes-dir.service
            placeholders-presuspend-setup.service
            kube-node-installation.service
            kube-node-configuration.service
            kubelet-monitor.service
            kube-logrotate.timer
            kube-logrotate.service
            kubernetes.target
        - systemctl start kubernetes.target
  - key: kube-env
    value: |
      ALLOCATE_NODE_CIDRS: "true"
      API_SERVER_TEST_LOG_LEVEL: --v=3
      AUTOSCALER_ENV_VARS: kube_reserved=cpu=1060m,memory=1019Mi,ephemeral-storage=41Gi;node_labels=cloud.google.com/gke-boot-disk=pd-balanced,cloud.google.com/gke-container-runtime=containerd,cloud.google.com/gke-cpu-scaling-level=2,cloud.google.com/gke-logging-variant=DEFAULT,cloud.google.com/gke-max-pods-per-node=110,cloud.google.com/gke-memory-gb-scaling-level=4,cloud.google.com/gke-netd-ready=true,cloud.google.com/gke-nodepool=cast-pool,cloud.google.com/gke-os-distribution=cos,cloud.google.com/gke-provisioning=standard,cloud.google.com/gke-stack-type=IPV4,cloud.google.com/machine-family=e2,cloud.google.com/private-node=false,iam.gke.io/gke-metadata-server-enabled=true;arch=amd64;os=linux;os_distribution=cos;evictionHard=memory.available=100Mi,nodefs.available=10%,nodefs.inodesFree=5%,pid.available=10%
      CA_CERT: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUVMVENDQXBXZ0F3SUJBZ0lSQU14WHdIb3R2T09WT2FONHhidnYvTzB3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa04yWTNaREprTWpVdE1tRXpNeTAwTkdNeExUaGtPREl0T1RJeU0yWTNNR1k1WVdFMQpNQ0FYRFRJMU1ERXpNREV3TXpBeU1Gb1lEekl3TlRVd01USXpNVEV6TURJd1dqQXZNUzB3S3dZRFZRUURFeVEzClpqZGtNbVF5TlMweVlUTXpMVFEwWXpFdE9HUTRNaTA1TWpJelpqY3daamxoWVRVd2dnR2lNQTBHQ1NxR1NJYjMKRFFFQkFRVUFBNElCandBd2dnR0tBb0lCZ1FEY3hFUW8xV2ZmMnZlL21ISDRIdU9zd0pINTNuK21jU0lKQ1R1Swpya0FoSEtBSVpkaDlaRHoxZWlxMVJJMnFDR0d0cUJRREF4U0ZnN3kydW9acSs4dkZkSUF4VmJMaXNyRmpzTTB1ClFEdUk4aGdDalRPUnBHdDNkUEsrUWRUTXlLOCttRCt0Ly90Z1AzQjVxdExPTE5ERW94ckdWbGxsUE95cTJyNEwKanlwSmx3RDVtRXFCc3h2WFlOSWRRUnpsOUpzQTg4QXlDRytWNGs4RStZUm0vRzZFWHN4bkRqVnc3Sm5aVEV5TwpTKzZhejBYQ2pFMEpjLzB6NnhGWUNpSXA5MStheGQvK2NCTmU0VFZUbXVGYlBiL25FNzFVNlBUdGFGTVd5K1drCkdMOWhGMC9SMlZWd3N1WVZvdnpuUmpISndYV3piakJGYkN5SGZNNHl5bXR1MU5NbnY4OEF6WWd0UE9obFQwSHIKdmcrNDNFRFZVaHlPSFVXUTludDZDNExVZytKck1sdFk4Zmsxb3gyTEhpUXN2QnN1aWxRRzgwZGt2UWhNb09wdApjckFEZmRPZkJKN3k2TjBrRXR4eWdUSUVXZ0h0ajd0MEd4Um9qWDdZbFBzS24rcW5hSHpCamZUNHRTT2ZBOUx2Cm04QlJIWFd6VmxGaTRWbFhwMW9qa0JKbnVvY0NBd0VBQWFOQ01FQXdEZ1lEVlIwUEFRSC9CQVFEQWdJRU1BOEcKQTFVZEV3RUIvd1FGTUFNQkFmOHdIUVlEVlIwT0JCWUVGT1o4bEMvNGl2NWI1QisxaXR5ZkRJYk12VjJwTUEwRwpDU3FHU0liM0RRRUJDd1VBQTRJQmdRQ3h4NnArUDh2N0N4OTd1SXd1Z09laGRSMGc3Wm9Ma0YxenkyZWpZNUxiCnpXeDlLbXhyMEZkZ3hCOTFoWHg4NldwdkZGOFlQT2NFL3VMc3pJeEQ5L29qd2l1a211dlpCd1QreDRLT1BrSlQKWFJML0tPS0dOc1lLdHZocUJVOTBRSm1XUGZvRWN6R1ltay91czRMemJvbkxqaTlWaXM1RzROL0RRR1Y2SjhVdwpuWnh5MzVkQU5BdnN6UlhkSm9mdzlHSWtMSmlhL0VQdU5rZnZqY21JY2h2V3NQVnl3cDdzeDAydjdpdWpnZDdxCmdIWTBsdnhxdHRidFgyMVZRZHpYNUtvbVhzR081ZmZmbzBrSHduZHRlR2dtc1FwWnhndGdBL1IvWXl0K2ZxYWEKQ00rT1dEd0pBaENtSkpmc3lTdjRURUtLMDVUOTZEOUVmYzBUdDRhVUowZnY1SFRyTkpralhXMDlwVWU3MGpUawpFT0lFN2R2NjRGS0M2ZmE3RFUyU0NFRnRmL2V0TFBQdXlGaFFkMHhYQXlKVExNNkZwTjdkQ3RzTy9ERWYxSGpGCnh4bXorSEswYXlsSE92NE1ycHB3aUJqNEdnc3FkTVBSQ2F3eWp0ZEFPNmxjNG01bWd4SzArQVl3Z3o5YTY1MWcKU3lLRURVSnZqWjIxWnJIQ1g2aFNaSms9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
      CLOUD_MONARCH_ENDPOINT: https://monitoring.googleapis.com/
      CLUSTER_IP_RANGE: 10.20.0.0/16
      CLUSTER_NAME: damian0130
      CONFIGURE_PGA: "true"
      CONTAINER_RUNTIME: containerd
      CONTAINER_RUNTIME_ENDPOINT: unix:///run/containerd/containerd.sock
      CONTAINER_RUNTIME_NAME: containerd
      CONTAINERD_DEPRECATION_CHECKER: "true"
      CONTAINERD_MAX_CONTAINER_LOG_LINE: "262144"
      CREATE_BOOTSTRAP_KUBECONFIG: "false"
      DETECT_LOCAL_MODE: NodeCIDR
      DETECT_MTU: "true"
      DNS_DOMAIN: cluster.local
      DNS_SERVER_IP: 10.30.0.10
      DOCKER_REGISTRY_MIRROR_URL: https://mirror.gcr.io
      ELASTICSEARCH_LOGGING_REPLICAS: "1"
      ENABLE_AUTH_PROVIDER_GCP: "true"
      ENABLE_CLUSTER_DNS: "true"
      ENABLE_CLUSTER_LOGGING: "false"
      ENABLE_CLUSTER_MONITORING: none
      ENABLE_CLUSTER_REGISTRY: "false"
      ENABLE_CLUSTER_UI: "true"
      ENABLE_CONNTRACK_EXEMPT_HC: "true"
      ENABLE_CONTAINERD_METRICS: "true"
      ENABLE_L7_LOADBALANCING: none
      ENABLE_LATEST_NPD: "true"
      ENABLE_METADATA_AGENT: ""
      ENABLE_METADATA_CONCEALMENT: "true"
      ENABLE_METRICS_SERVER: "true"
      ENABLE_NETD: "true"
      ENABLE_NODE_BFQ_IO_SCHEDULER: "true"
      ENABLE_NODE_LOGGING: "false"
      ENABLE_NODE_PROBLEM_DETECTOR: standalone
      ENABLE_NODE_REGISTRATION_CHECKER: "true"
      ENABLE_NODELOCAL_DNS: "false"
      ENABLE_SHM_HEALTHCHECK_BINARIES: "true"
      ENABLE_SYSCTL_TUNING: "true"
      ENV_TIMESTAMP: "2025-01-30T11:30:19+00:00"
      EXTRA_DOCKER_OPTS: --insecure-registry 10.0.0.0/8
      EXTRA_POD_SYSCTLS: net.ipv6.conf.all.disable_ipv6=1,net.ipv6.conf.default.disable_ipv6=1
      FEATURE_GATES: DisableKubeletCloudCredentialProviders=true,RotateKubeletServerCertificate=true,ExecProbeTimeout=false
      FLUENTD_CONTAINER_RUNTIME_SERVICE: containerd
      GVISOR_HOST_SETTINGS: enforce
      GVISOR_METRIC_SERVER: 127.0.0.1:9115
      HEAPSTER_USE_NEW_STACKDRIVER_RESOURCES: "true"
      HEAPSTER_USE_OLD_STACKDRIVER_RESOURCES: "false"
      HPA_USE_REST_CLIENTS: "true"
      INSTANCE_PREFIX: gke-damian0130-1b5b43fd
      KUBE_ADDON_REGISTRY: k8s.gcr.io
      KUBE_CLUSTER_DNS: 10.30.0.10
      KUBE_DOCKER_REGISTRY: europe-central2-artifactregistry.gcr.io/gke-release/gke-release
      KUBE_MANIFESTS_TAR_HASH: 1419d776a0949d18746305db7582e2361dc48950a31a3b4afe2f91800e5203fa1fca13f5078d8d13bb51e4ddb95fe485c95e5773a64dfb37f5d489f45b11d22d
      KUBE_MANIFESTS_TAR_URL: https://storage.googleapis.com/gke-release-eu/kubernetes/release/v1.31.4-gke.1183000/kubernetes-manifests.tar.gz,https://storage.googleapis.com/gke-release/kubernetes/release/v1.31.4-gke.1183000/kubernetes-manifests.tar.gz,https://storage.googleapis.com/gke-release-asia/kubernetes/release/v1.31.4-gke.1183000/kubernetes-manifests.tar.gz
      KUBE_PROXY_TOKEN: I1HTlWutYvPpeVMvpPJPn_GyrDrADb5518LkODxMnI0=
      KUBELET_ARGS: --v=2 --cloud-provider=external --experimental-mounter-path=/home/kubernetes/containerized_mounter/mounter --cert-dir=/var/lib/kubelet/pki/ --kubeconfig=/var/lib/kubelet/kubeconfig --image-credential-provider-config=/etc/srv/kubernetes/cri_auth_config.yaml --image-credential-provider-bin-dir=/home/kubernetes/bin --max-pods=110 --node-labels=beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,cloud.google.com/gke-boot-disk=pd-balanced,cloud.google.com/gke-container-runtime=containerd,cloud.google.com/gke-cpu-scaling-level=2,cloud.google.com/gke-logging-variant=DEFAULT,cloud.google.com/gke-max-pods-per-node=110,cloud.google.com/gke-memory-gb-scaling-level=4,cloud.google.com/gke-netd-ready=true,cloud.google.com/gke-os-distribution=cos,cloud.google.com/gke-provisioning=standard,cloud.google.com/gke-stack-type=IPV4,cloud.google.com/machine-family=e2,cloud.google.com/private-node=false,iam.gke.io/gke-metadata-server-enabled=true,kubernetes.io/arch=amd64,kubernetes.io/os=linux,provisioner.cast.ai/managed-by=cast.ai,provisioner.cast.ai/node-configuration-id=cfa3e152-dc4e-45f1-b991-fb13170e7f6b,provisioner.cast.ai/node-configuration-name=default,provisioner.cast.ai/node-configuration-version=5,provisioner.cast.ai/node-id=4a209c2c-28d3-471e-9312-9d207a6e2dd2,scheduling.cast.ai/node-template-version=1,scheduling.cast.ai/node-template=default-by-castai,scheduling.cast.ai/on-demand=true,topology.cast.ai/csp=gcp,volume.scheduling.cast.ai/pd-balanced=true,volume.scheduling.cast.ai/pd-ssd=true,volume.scheduling.cast.ai/pd-standard=true --volume-plugin-dir=/home/kubernetes/flexvolume --node-status-max-images=25 --container-runtime-endpoint=unix:///run/containerd/containerd.sock --runtime-cgroups=/system.slice/containerd.service --registry-qps=10 --registry-burst=20 --register-with-taints=
      KUBELET_HTTP2_PING_TIMEOUT_SECONDS: "5"
      KUBELET_HTTP2_READ_IDLE_TIMEOUT_SECONDS: "10"
      KUBELET_VERSION: v1.31.4-gke.1183000
      KUBERNETES_MASTER: "false"
      KUBERNETES_MASTER_NAME: 10.0.0.2
      LOAD_IMAGE_COMMAND: ctr -n=k8s.io images import
      LOGGING_DESTINATION: ""
      LOGGING_STACKDRIVER_RESOURCE_TYPES: ""
      MONITORING_FLAG_SET: "true"
      NETWORK_PROVIDER: cni
      NODE_BFQ_IO_SCHEDULER_IO_WEIGHT: "1200"
      NODE_LOCAL_SSDS_EXT: ""
      NON_MASQUERADE_CIDR: 0.0.0.0/0
      REMOUNT_VOLUME_PLUGIN_DIR: "true"
      REQUIRE_METADATA_KUBELET_CONFIG_FILE: "true"
      SALT_TAR_HASH: ""
      SALT_TAR_URL: https://storage.googleapis.com/gke-release-eu/kubernetes/release/v1.31.4-gke.1183000/kubernetes-salt.tar.gz,https://storage.googleapis.com/gke-release/kubernetes/release/v1.31.4-gke.1183000/kubernetes-salt.tar.gz,https://storage.googleapis.com/gke-release-asia/kubernetes/release/v1.31.4-gke.1183000/kubernetes-salt.tar.gz
      SERVER_BINARY_TAR_HASH: cfc9348adf3d58c8b11591a6990ec77d7ffba3591b0bfc03342622dcc566eea166eef28fbee9b5e4510f9573516417ec4d0b5dcf287e61c5eb935653f725ef43
      SERVER_BINARY_TAR_URL: https://storage.googleapis.com/gke-release-eu/kubernetes/release/v1.31.4-gke.1183000/kubernetes-server-linux-amd64.tar.gz,https://storage.googleapis.com/gke-release/kubernetes/release/v1.31.4-gke.1183000/kubernetes-server-linux-amd64.tar.gz,https://storage.googleapis.com/gke-release-asia/kubernetes/release/v1.31.4-gke.1183000/kubernetes-server-linux-amd64.tar.gz
      SERVICE_CLUSTER_IP_RANGE: 10.30.0.0/24
      STACKDRIVER_ENDPOINT: https://logging.googleapis.com
      STORAGE_ENDPOINT: https://storage.googleapis.com
      SYSCTL_OVERRIDES: ""
      TPM_BOOTSTRAP_CERT: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURyRENDQWhTZ0F3SUJBZ0lSQU1SUm05SXZLVDYwdkV0dXdSM2dmeHd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa04yWTNaREprTWpVdE1tRXpNeTAwTkdNeExUaGtPREl0T1RJeU0yWTNNR1k1WVdFMQpNQjRYRFRJMU1ERXpNREV4TWpneU1Wb1hEVE13TURFeU9URXhNekF5TVZvd0hERWFNQmdHQTFVRUF4TVJhM1ZpClpXeGxkQzFpYjI5MGMzUnlZWEF3Z2dFaU1BMEdDU3FHU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLQW9JQkFRQ1YKRmhUTFQ0bEJMU2VJNFlrSGg2SjlmaFcwZytydTFDbDN5eEFQU1Zud1RhRTBQa0hWNmQzb3h1VlRiZWFnMWVWdQpyMDNobzNVa0N2dlgzZzA5bzUzb2NnbEdxeVNjTm5Nci9FZ05xOXp5c29JSHBnaWtaZFF4b2NWMUM3TlQ1a25pCkNxWlNIRHlhalc0eVZOTE5BcnRFckhxT2hmQ21kdjBkN2h0U3g1Zml5Smc2clJORy8xalVua0ZIMndOVExDZkIKb2U0L1lGcEpZYzFrTE1sdGxKcnp0c3Z3bFFiVVh3UXp1cUNsUTg4TVBIQVh2TnZzVGJaVHZUQXZVMGE3SS9iUApDRVFIZVFBeWliaWFhYW9NWG1pTmtsSmhEamh6T1A3ZUtwMWQ0NXN2cWZLY21aSFYrWC9KZkdCS1hhWHpkQlVjCjZKQ05IcjBLNS9JbVlUbjhYQWJUQWdNQkFBR2pWakJVTUE0R0ExVWREd0VCL3dRRUF3SUZvREFUQmdOVkhTVUUKRERBS0JnZ3JCZ0VGQlFjREFqQU1CZ05WSFJNQkFmOEVBakFBTUI4R0ExVWRJd1FZTUJhQUZPWjhsQy80aXY1Ygo1QisxaXR5ZkRJYk12VjJwTUEwR0NTcUdTSWIzRFFFQkN3VUFBNElCZ1FDbk9YaDVqNk10M0xBbkdFbzZEeTZ3CjhvQ3B6YlNUSHVIUzlsSHJyeUZTMDJPT0IwcGJCbEdhWHlmU1FoODVrWkZya3BCNlNuNTdSTm95WjRoRm1CazQKSHM2SVlCTVdwWFNYR1FMY1dLYXZXQUlSM0Qydzg2RVdsTTY4OEtIZlh6a1JtejN0TFJkMlUxbHpZTGN1VjZTTQoyaU9Pd2tIMFQrQmpoUmlkMWpFUWxSTWhyVzB5UlRmbGcwUzA2eDQ3akZrZ0dHTXhES3RHbmtyRlNsTlhLbUhjCjVDMzY4UlRSOXVkazdzWisxRXNtOUJ2ZmVpNGVUQmliTjdXMHg2Y1JTOWw1dUhzWlVmZElET2lXK0FKTEw5eFIKY0dIbHVxSFFzV3djOFBqN0drazgzSmhzV0pXS1pkUitjQTR1Und6enlFc2J4amJpN0tkelZXd01RZWl4YVZCNgpWV3hQRWVRUGZuNmZ3RUpZQnVYb1huNHFNNXpGenJNbGNpSHF2ZGs1RFZNUVVMaVBCd3N4b2cxM0tUeW5nU3JaCnRFNGtxOHBnM2NlY3BFdG9jZ2RuOWpHaXNHMEJzUDY0STByKzRXbFdxUEdHWlhXWnluMkFlaUp2OGpkYUlEbjQKdDlRZE1leGNtcjA5amtsNXMrZzdjOXpUSUIxZWVJa3ZEalo5UGdZUG9WVT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
      TPM_BOOTSTRAP_KEY: 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
      VOLUME_PLUGIN_DIR: /home/kubernetes/flexvolume
      ZONE: europe-central2
  - key: node_pool
    value: default-node-pool
  - key: serial-port-logging-enable
    value: 'true'
  - key: kubelet-config
    value: |
      apiVersion: kubelet.config.k8s.io/v1beta1
      authentication:
          anonymous:
              enabled: false
          webhook:
              enabled: true
          x509:
              clientCAFile: /etc/srv/kubernetes/pki/ca-certificates.crt
      authorization:
          mode: Webhook
      cgroupRoot: /
      clusterDNS:
          - 10.30.0.10
      clusterDomain: cluster.local
      enableDebuggingHandlers: true
      evictionHard:
          memory.available: 100Mi
          nodefs.available: 10%
          nodefs.inodesFree: 5%
          pid.available: 10%
      featureGates:
          DisableKubeletCloudCredentialProviders: true
          ExecProbeTimeout: false
          RotateKubeletServerCertificate: true
      kernelMemcgNotification: true
      kind: KubeletConfiguration
      kubeReserved:
          cpu: 70m
          ephemeral-storage: 59Gi
          memory: 1843Mi
      maxParallelImagePulls: 3
      maxPods: 110
      readOnlyPort: 10255
      serializeImagePulls: false
      serverTLSBootstrap: true
      staticPodPath: /etc/kubernetes/manifests
  - key: cluster-name
    value: damian0130
  - key: cluster-location
    value: europe-central2
  - key: cast-pool-version
    value: v1
  - key: kube-labels
    value: beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,cloud.google.com/gke-boot-disk=pd-balanced,cloud.google.com/gke-container-runtime=containerd,cloud.google.com/gke-cpu-scaling-level=2,cloud.google.com/gke-logging-variant=DEFAULT,cloud.google.com/gke-max-pods-per-node=110,cloud.google.com/gke-memory-gb-scaling-level=4,cloud.google.com/gke-netd-ready=true,cloud.google.com/gke-os-distribution=cos,cloud.google.com/gke-provisioning=standard,cloud.google.com/gke-stack-type=IPV4,cloud.google.com/machine-family=e2,cloud.google.com/private-node=false,iam.gke.io/gke-metadata-server-enabled=true,kubernetes.io/arch=amd64,kubernetes.io/os=linux,provisioner.cast.ai/managed-by=cast.ai,provisioner.cast.ai/node-configuration-id=cfa3e152-dc4e-45f1-b991-fb13170e7f6b,provisioner.cast.ai/node-configuration-name=default,provisioner.cast.ai/node-configuration-version=5,provisioner.cast.ai/node-id=4a209c2c-28d3-471e-9312-9d207a6e2dd2,scheduling.cast.ai/node-template-version=1,scheduling.cast.ai/node-template=default-by-castai,scheduling.cast.ai/on-demand=true,topology.cast.ai/csp=gcp,volume.scheduling.cast.ai/pd-balanced=true,volume.scheduling.cast.ai/pd-ssd=true,volume.scheduling.cast.ai/pd-standard=true
  kind: compute#metadata
name: gke-damian0130-cast-pool-4a209c2c
networkInterfaces:
- accessConfigs:
  - kind: compute#accessConfig
    name: external-nat
    natIP: 34.118.25.217
    networkTier: PREMIUM
    type: ONE_TO_ONE_NAT
  aliasIpRanges:
  - ipCidrRange: 10.20.1.0/24
    subnetworkRangeName: damian0130-ip-range-pods
  fingerprint: p5DohGf2soQ=
  kind: compute#networkInterface
  name: nic0
  network: https://www.googleapis.com/compute/v1/projects/engineering-test-353509/global/networks/damian0130
  networkIP: 10.0.0.12
  stackType: IPV4_ONLY
  subnetwork: https://www.googleapis.com/compute/v1/projects/engineering-test-353509/regions/europe-central2/subnetworks/damian0130-ip-range-nodes
satisfiesPzi: true
scheduling:
  automaticRestart: true
  onHostMaintenance: MIGRATE
  preemptible: false
  provisioningModel: STANDARD
selfLink: https://www.googleapis.com/compute/v1/projects/engineering-test-353509/zones/europe-central2-a/instances/gke-damian0130-cast-pool-4a209c2c
serviceAccounts:
- email: tf-gke-damian0130-o2rt@engineering-test-353509.iam.gserviceaccount.com
  scopes:
  - https://www.googleapis.com/auth/cloud-platform
shieldedInstanceConfig:
  enableIntegrityMonitoring: true
  enableSecureBoot: true
  enableVtpm: true
shieldedInstanceIntegrityPolicy:
  updateAutoLearnPolicy: true
startRestricted: false
status: RUNNING
tags:
  fingerprint: 3vbLIxpak58=
  items:
  - gke-damian0130-1b5b43fd-node
zone: https://www.googleapis.com/compute/v1/projects/engineering-test-353509/zones/europe-central2-a
